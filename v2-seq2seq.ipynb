{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c55e2298",
   "metadata": {},
   "source": [
    "# V2: SEQ2SEQ\n",
    "\n",
    "This notebook follows [an online tutorial](https://www.tensorflow.org/text/tutorials/nmt_with_attention#create_a_tfdata_dataset)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "71899cc9-86b4-4eda-b525-d818661c70a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-05 19:32:43.812420: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-09-05 19:32:43.818567: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-09-05 19:32:43.831683: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-09-05 19:32:43.850292: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-09-05 19:32:43.854793: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-09-05 19:32:43.866789: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-09-05 19:32:44.813492: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa459db2-5a48-4bac-8cbd-38496888faee",
   "metadata": {},
   "source": [
    "**Notes**:\n",
    "- This notebook follows [an online tutorial](https://www.tensorflow.org/text/tutorials/nmt_with_attention) (and [at least one other](https://www.tensorflow.org/text/tutorials/text_generation) of the Tensorflow tutorials).\n",
    "- This [blog post](https://janakiev.com/blog/jupyter-virtual-envs/) was referenced to set up the virtual environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "92b150ba-48c0-4f33-8d08-b9f363d6fcfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from typing import Any, Tuple\n",
    "from IPython.display import display, Markdown\n",
    "from pathlib import Path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5faca0eb-c672-4d1c-884f-b5ba38a22b63",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_file_paths = list(Path('data/processed/en/').glob('*.txt'))\n",
    "dataset_raw = tf.data.TextLineDataset(\n",
    "\tdata_file_paths,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5890fa88",
   "metadata": {},
   "source": [
    "We've now loaded the `.txt` training data files using [`tf.data.TextLineDataset`](https://www.tensorflow.org/api_docs/python/tf/data/TextLineDataset). Each line in the source files is mapped to a new training example. \n",
    "\n",
    "Although some preprocessing has been done by `/data/process_data.py`, paragraphs aren't filtered out based on length/content. Let's do that now:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ff5c607d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_paragraphs(context, target):\n",
    "\treturn tf.strings.length(context) > 5\n",
    "\n",
    "punctuation_chars = r'\\?!.,\"\\-\\':'\n",
    "def add_context(target):\n",
    "\tcontext = tf.strings.regex_replace(target, '[{}]+'.format(punctuation_chars), '')\n",
    "\tcontext = tf.strings.strip(\n",
    "\t\ttf.strings.regex_replace(context, '[ ]+', ' ')\n",
    "\t)\n",
    "\tcontext = tf.strings.lower(context)\n",
    "\treturn context, target\n",
    "\n",
    "dataset_raw = dataset_raw.map(add_context).filter(filter_paragraphs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "346b9d94",
   "metadata": {},
   "source": [
    "Now let's inspect the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3646c389",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'illustration' b'Illustration '\n",
      "b'alices adventures in wonderland' b\"Alice's Adventures in Wonderland\"\n",
      "b'by lewis carroll' b'by Lewis Carroll'\n",
      "b'the millennium fulcrum edition 30' b'THE MILLENNIUM FULCRUM EDITION 3.0'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-05 19:32:45.481673: I tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    }
   ],
   "source": [
    "for text, label in dataset_raw.take(4).as_numpy_iterator():\n",
    "\tprint(text, label)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e24075a",
   "metadata": {},
   "source": [
    "### Batching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "197d8b27",
   "metadata": {},
   "outputs": [],
   "source": [
    "BUFFER_SIZE = 100_000\n",
    "BATCH_SIZE = 16\n",
    "dataset_train = dataset_raw.shuffle(BUFFER_SIZE).batch(BATCH_SIZE)\n",
    "\n",
    "# Inspired by https://stackoverflow.com/a/74609848.\n",
    "validate_size = 64\n",
    "dataset_validate = dataset_train.take(validate_size)\n",
    "dataset_train = dataset_train.skip(validate_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3532db30",
   "metadata": {},
   "source": [
    "### Preparing to process data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1aa159e6",
   "metadata": {},
   "source": [
    "The [`TextVectorization`](https://www.tensorflow.org/api_docs/python/tf/keras/layers/TextVectorization) layer takes a `standardize` option that preprocesses input data. The default removes punctuation, but we don't want that. Let's redefine it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f74b9fb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(b\"[START] [cap] this is a test ! [cap] it ' s working ? ! [END]\", shape=(), dtype=string)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def standardize_tf_text(text):\n",
    "\tpunctuation_regex = '[{p}]'.format(p = punctuation_chars)\n",
    "\n",
    "\t# Surround punctuation with spaces for easier tokenization\n",
    "\ttext = tf.strings.regex_replace(text, punctuation_regex, r' \\0 ')\n",
    "\n",
    "\t# Remove repeated spaces\n",
    "\ttext = tf.strings.regex_replace(text, r'\\s+', ' ')\n",
    "\n",
    "\t# Add a special \"capitalize the next letter\" token\n",
    "\ttext = tf.strings.regex_replace(text, r'(\\s|^)([A-Z])', r' [CAP] \\2')\n",
    "\n",
    "\t# Lowercase everything\n",
    "\ttext = tf.strings.lower(text)\n",
    "\n",
    "\t# Remove leading and trailing spaces\n",
    "\ttext = tf.strings.strip(text)\n",
    "\n",
    "\t# Add sequence markings\n",
    "\treturn tf.strings.join(['[START]', text, '[END]'], separator=' ')\n",
    "\n",
    "print(standardize_tf_text('This is a test! It\\'s working?!'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "018456b9",
   "metadata": {},
   "source": [
    "The text standardization function can now be used to preprocess text:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "87815e69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 14 target words: ['', '[UNK]', '[cap]', ',', 'the', '.', '[START]', '[END]', 'and', 'to', 'of', 'i', 'a', 'in']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-05 19:32:55.540937: I tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    }
   ],
   "source": [
    "# Keep only the 2000 most commonly used tokens\n",
    "max_vocab_size = 2000\n",
    "\n",
    "target_text_processor = tf.keras.layers.TextVectorization(\n",
    "\tstandardize=standardize_tf_text,\n",
    "\tmax_tokens=max_vocab_size,\n",
    "\t# Allow entries of different lengths\n",
    "\tragged=True,\n",
    ")\n",
    "target_text_processor.adapt(dataset_train.map(lambda context, target: target))\n",
    "\n",
    "print('First 14 target words:', target_text_processor.get_vocabulary()[:14])\n",
    "\n",
    "# The target data should be roughly equivalent to the context data, except have additional (punctuation)\n",
    "# tokens.\n",
    "context_text_processor = target_text_processor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "047d66c3",
   "metadata": {},
   "source": [
    "We can use these layers to convert to/from token IDs:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7b4789f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example tokens tf.Tensor([  6   1 257  42  24  12   1   1  24   1  42   7], shape=(12,), dtype=int64)\n",
      "Back to text [START] [UNK] world this is a [UNK] [UNK] is [UNK] this [END]\n"
     ]
    }
   ],
   "source": [
    "example_text = 'hello world this is a test tensorflow is processing this'\n",
    "example_tokens = context_text_processor(example_text)\n",
    "print('Example tokens', example_tokens)\n",
    "\n",
    "context_vocab = np.array(context_text_processor.get_vocabulary())\n",
    "tokens = context_vocab[example_tokens.numpy()]\n",
    "print('Back to text', ' '.join(tokens))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "431d8e67",
   "metadata": {},
   "source": [
    "### Processing the data\n",
    "\n",
    "Now, we'll:\n",
    "1. Map the data through the text processors we just made.\n",
    "2. Shift the target data, so that our network is provided with a history of generated tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2efef357",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_text(context, target):\n",
    "\treturn context_text_processor(context), target_text_processor(target)\n",
    "\n",
    "def add_target_history(context, target):\n",
    "\t# .to_tensor(): Converts from RaggedTensors to Tensors.\n",
    "\t# We give our network the history as target_in\n",
    "\ttarget_in = target[:, :-1].to_tensor()\n",
    "\ttarget_out = target[:, 1:].to_tensor()\n",
    "\treturn (context.to_tensor(), target_in), target_out\n",
    "dataset_train = dataset_train.map(process_text).map(add_target_history).repeat()\n",
    "dataset_validate = dataset_validate.map(process_text).map(add_target_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "50594897",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context [START],yet,the,character,of,his,face,had,been,at,all,times,remarkable,[END],,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,\n",
      "target_in [START],[cap],yet,the,character,of,his,face,had,been,at,all,times,remarkable,.,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,\n",
      "target_out [cap],yet,the,character,of,his,face,had,been,at,all,times,remarkable,.,[END],,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def inspect_dataset(dataset: tf.data.Dataset):\n",
    "\ttarget_vocab = np.array(target_text_processor.get_vocabulary())\n",
    "\tfor (context, target_in), target_out in dataset.take(1):\n",
    "\t\tcontext_words = context_vocab[context[0]]\n",
    "\t\tprint('context', ','.join(context_words))\n",
    "\t\tprint('target_in', ','.join(target_vocab[target_in[0]]))\n",
    "\t\tprint('target_out', ','.join(target_vocab[target_out[0]]))\n",
    "\n",
    "inspect_dataset(dataset_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec63bc6c",
   "metadata": {},
   "source": [
    "## Model\n",
    "\n",
    "### The encoder\n",
    "\n",
    "See https://www.tensorflow.org/text/tutorials/nmt_with_attention#the_encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "83f026f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(tf.keras.Layer):\n",
    "\tdef __init__(self, text_processor, units: int):\n",
    "\t\t\"\"\"\n",
    "\t\tCreates a new Encoder layer. [dimen] is the maxiumum number of elements of the input\n",
    "\t\tthat can be processed by the encoder.\n",
    "\t\t\"\"\"\n",
    "\t\tsuper(Encoder, self).__init__()\n",
    "\t\tself.text_processor = text_processor\n",
    "\t\tself.vocab_size = text_processor.vocabulary_size()\n",
    "\t\tself.units = units\n",
    "\n",
    "\t\t# Converts tokens -> vectors\n",
    "\t\tself.embedding = tf.keras.layers.Embedding(\n",
    "\t\t\t# mask_zero: Treats zero as a padding value that should be ignored\n",
    "\t\t\tself.vocab_size, units, mask_zero = True,\n",
    "\t\t)\n",
    "\t\tgru = tf.keras.layers.GRU(\n",
    "\t\t\tunits, return_sequences = True,\n",
    "\t\t\t# Use the recurrent_initializer suggested by the tutorial (& the default\n",
    "\t\t\t# for kernel_initializer).\n",
    "\t\t\trecurrent_initializer='glorot_uniform'\n",
    "\t\t)\n",
    "\t\tself.rnn = tf.keras.layers.Bidirectional(\n",
    "\t\t\t# merge_mode determines how the forward and backward layers are combined\n",
    "\t\t\t#            'concat' is another option here\n",
    "\t\t\tmerge_mode = 'sum',\n",
    "\t\t\tlayer=gru,\n",
    "\t\t)\n",
    "\n",
    "\tdef call(self, x):\n",
    "\t\tx = self.embedding(x)\n",
    "\t\tx = self.rnn(x)\n",
    "\t\treturn x\n",
    "\n",
    "\tdef prepare_for_input(self, texts):\n",
    "\t\t\"\"\"\n",
    "\t\tUtility method that converts `texts` to a form that can be provided to the `call` method.\n",
    "\t\t\"\"\"\n",
    "\t\ttexts = tf.convert_to_tensor(texts)\n",
    "\t\tif len(texts.shape) == 0:\n",
    "\t\t\ttexts = texts[None]\n",
    "\t\tcontext = self.text_processor(texts).to_tensor()\n",
    "\t\treturn context\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ea196ff",
   "metadata": {},
   "source": [
    "Try it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "331e474b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Context tokens shape (batch, s): (16, 46)\n",
      "Encoder output shape (batch, s, ENCODER_UNITS): (16, 46, 48)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-05 19:33:01.819845: I tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    }
   ],
   "source": [
    "ENCODER_UNITS = 48\n",
    "encoder = Encoder(context_text_processor, ENCODER_UNITS)\n",
    "\n",
    "for (context, target_history), target_next in dataset_validate.take(1):\n",
    "\tencoder_result = encoder(context)\n",
    "\tprint('Context tokens shape (batch, s):', context.shape)\n",
    "\tprint('Encoder output shape (batch, s, ENCODER_UNITS):', encoder_result.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dbd7fb6",
   "metadata": {},
   "source": [
    "### The attention layer\n",
    "\n",
    "Attention can be thought of as training a lookup table with keys and values. The lookup table has inputs `values` and `query`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "781b2e8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CrossAttention(tf.keras.Layer):\n",
    "\tdef __init__(self, units, **kwargs):\n",
    "\t\tsuper().__init__()\n",
    "\t\tself.attention_layer = tf.keras.layers.MultiHeadAttention(\n",
    "\t\t\tkey_dim=units,\n",
    "\t\t\tnum_heads=1,\n",
    "\t\t\t**kwargs\n",
    "\t\t)\n",
    "\t\t# Keeps \"the mean activation within each example close to 0 and the\n",
    "\t\t# activation standard deviation close to 1\" -- https://www.tensorflow.org/api_docs/python/tf/keras/layers/LayerNormalization?hl=en\n",
    "\t\tself.norm_layer = tf.keras.layers.LayerNormalization()\n",
    "\t\tself.add_layer = tf.keras.layers.Add()\n",
    "\t\tself.supports_masking = True\n",
    "\n",
    "\tdef call(self, query, value):\n",
    "\t\tattention_output = self.attention_layer(\n",
    "\t\t\tquery = query,\n",
    "\t\t\tvalue = value,\n",
    "\t\t\t#use_causal_mask=True,\n",
    "\t\t\t# Return the attention scores for latter plotting\n",
    "\t\t\t# return_attention_scores = True,\n",
    "\t\t)\n",
    "\n",
    "\t\tx = self.add_layer([ query, attention_output ])\n",
    "\t\tx = self.norm_layer(x)\n",
    "\t\treturn x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1c8857ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoded context sequence shape (batch, s, units): (16, 52, 48)\n",
      "Target history sequence shape (batch, t, units): (16, 63, 48)\n",
      "Attention result shape (batch, t, units): (16, 63, 48)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/self/Documents/punctuation-fixer/env/lib64/python3.11/site-packages/keras/src/layers/layer.py:934: UserWarning: Layer 'query' (of type EinsumDense) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
      "  warnings.warn(\n",
      "/home/self/Documents/punctuation-fixer/env/lib64/python3.11/site-packages/keras/src/layers/layer.py:934: UserWarning: Layer 'key' (of type EinsumDense) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
      "  warnings.warn(\n",
      "/home/self/Documents/punctuation-fixer/env/lib64/python3.11/site-packages/keras/src/layers/layer.py:934: UserWarning: Layer 'value' (of type EinsumDense) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "attention_layer = CrossAttention(ENCODER_UNITS)\n",
    "\n",
    "# Test with an example\n",
    "for (context, target_history), target_next in dataset_validate.take(1):\n",
    "\tembed_layer = tf.keras.layers.Embedding(target_text_processor.vocabulary_size(), output_dim=ENCODER_UNITS, mask_zero=True)\n",
    "\ttarget_embed = embed_layer(target_history)\n",
    "\tencoded_context = encoder(context)\n",
    "\tattention_result = attention_layer(target_embed, encoded_context)\n",
    "\n",
    "\tprint('Encoded context sequence shape (batch, s, units):', encoded_context.shape)\n",
    "\tprint('Target history sequence shape (batch, t, units):', target_embed.shape)\n",
    "\tprint('Attention result shape (batch, t, units):', attention_result.shape)\n",
    "\n",
    "\t# Used later \n",
    "\ttest_encoded_context = encoded_context"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f5577a1",
   "metadata": {},
   "source": [
    "### The decoder\n",
    "\n",
    "The decoder produces queries for the attention layer. The decoder operates on `target_history`. At each step during training, it should have no information about future target output (that's what we're trying to determine). As such, we use a unidirectional RNN.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2454259d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDense(tf.keras.layers.Dense):\n",
    "\tdef __init__(self, *args, **kwargs):\n",
    "\t\tsuper(CustomDense, self).__init__(*args, **kwargs)\n",
    "\t\n",
    "\tdef compute_mask(self, _inputs, mask=None):\n",
    "\t\treturn mask\n",
    "\n",
    "class Decoder(tf.keras.Layer):\n",
    "\tdef __init__(self, text_processor, units):\n",
    "\t\tsuper(Decoder, self).__init__()\n",
    "\t\tself.text_processor = text_processor\n",
    "\t\tself.vocab_size = text_processor.vocabulary_size()\n",
    "\t\tself.units = units\n",
    "\n",
    "\t\tself.embedding_layer = tf.keras.layers.Embedding(\n",
    "\t\t\t# mask_zero: Treats zero as a padding value that should be ignored\n",
    "\t\t\tself.vocab_size, units, mask_zero = True,\n",
    "\t\t)\n",
    "\t\tself.rnn_layer = tf.keras.layers.GRU(\n",
    "\t\t\tunits, return_sequences = True, return_state = True, recurrent_initializer='glorot_uniform',\n",
    "\t\t)\n",
    "\t\tself.attention_layer = CrossAttention(units)\n",
    "\n",
    "\t\t# Creates logits with the estimated probability of each output token\n",
    "\t\tself.output_layer = CustomDense(self.vocab_size)\n",
    "\n",
    "\t\t# Conversion:\n",
    "\t\tself.word_to_id = tf.keras.layers.StringLookup(\n",
    "\t\t\tvocabulary = text_processor.get_vocabulary(),\n",
    "\t\t\tmask_token = '',\n",
    "\t\t\toov_token = '[UNK]',\n",
    "\t\t)\n",
    "\t\tself.id_to_word = tf.keras.layers.StringLookup(\n",
    "\t\t\tvocabulary = text_processor.get_vocabulary(),\n",
    "\t\t\tmask_token = '',\n",
    "\t\t\toov_token = '[UNK]',\n",
    "\t\t\tinvert = True,\n",
    "\t\t)\n",
    "\t\t# Pre-computing these simplifies exporting\n",
    "\t\tself.start_id = self.word_to_id('[START]')\n",
    "\t\tself.end_id = self.word_to_id('[END]')\n",
    "\n",
    "\t\tself.supports_masking = True\n",
    "\t\n",
    "\tdef build(self, input_shape):\n",
    "\t\t# Nothing tha needs a size allocation based on the input shape\n",
    "\t\tpass\n",
    "\t\n",
    "\tdef call(self, context, target_history, state = None, return_state = False):\n",
    "\t\tx = self.embedding_layer(target_history)\n",
    "\t\tx, state = self.rnn_layer(x, initial_state = state)\n",
    "\t\tx = self.attention_layer(x, context)\n",
    "\n",
    "\t\tlogits = self.output_layer(x)\n",
    "\t\tif return_state:\n",
    "\t\t\treturn logits, state\n",
    "\t\telse:\n",
    "\t\t\treturn logits\n",
    "\t\n",
    "\t## Conversion/testing ##\n",
    "\n",
    "\tdef tokens_to_text(self, tokens):\n",
    "\t\ttext = tf.strings.reduce_join(self.id_to_word(tokens), separator = ' ')\n",
    "\t\ttext = tf.strings.regex_replace(text, r'\\s*\\[START\\]\\s*', '')\n",
    "\t\ttext = tf.strings.regex_replace(text, r'\\s*\\[END\\].*$', '')\n",
    "\t\treturn text\n",
    "\n",
    "\tdef generate_next_token(self, context, target_history, done_vec, state, temperature = 0.0):\n",
    "\t\t# Note: is_done is a vector, indicating whether each item in the batch is done\n",
    "\n",
    "\t\tlogits, state = self(context, target_history, state = state, return_state = True)\n",
    "\n",
    "\t\t# logits has shape (batch, t, target_vocab_size). Only generate the token corresponding\n",
    "\t\t# to the last logits in the sequence (at t - 1)\n",
    "\t\tif temperature > 0:\n",
    "\t\t\tnext_token = tf.where(\n",
    "\t\t\t\tdone_vec,\n",
    "\t\t\t\ttf.constant(0, dtype=tf.int64), # Emit 0 after a sequence is done\n",
    "\t\t\t\ttf.random.categorical(logits[:, -1, :] / temperature, num_samples = 1), # Otherwise, pick the token from a categorical distribution\n",
    "\t\t\t)\n",
    "\t\telse:\n",
    "\t\t\tnext_token = tf.math.argmax(logits, axis=-1)\n",
    "\t\tdone_vec = done_vec|(next_token == self.end_id)\n",
    "\t\treturn next_token, done_vec, state\n",
    "\t\n",
    "\tdef get_initial_state(self, context):\n",
    "\t\t# context has shape (batch_size, s, units)\n",
    "\t\tbatch_size = tf.shape(context)[0]\n",
    "\t\tstart_tokens = tf.fill([batch_size, 1], self.start_id)\n",
    "\t\tdone_vec = tf.zeros([batch_size, 1], dtype = tf.bool)\n",
    "\n",
    "\t\t# From the Tensorflow source code:\n",
    "\t\t# > RNN expect the states in a list, even if single state.\n",
    "\t\t# Note: Without the [0] we get a type mismatch while exporting.\n",
    "\t\tinitial_state = self.rnn_layer.get_initial_state(batch_size)[0]\n",
    "\n",
    "\t\treturn start_tokens, done_vec, initial_state"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8d5ccb1",
   "metadata": {},
   "source": [
    "Let's try it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "219a3522",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output: b'villefort dim terror laid fixed pressed pain stapletonvillefort dim terror laid fixed pressed pain stapletonvillefort dim terror laid fixed pressed pain stapleton'\n"
     ]
    }
   ],
   "source": [
    "def test_generation_loop():\n",
    "\tdecoder = Decoder(target_text_processor, ENCODER_UNITS)\n",
    "\tnext_token, done_vec, state = decoder.get_initial_state(test_encoded_context[:3, :, :])\n",
    "\ttokens = [next_token]\n",
    "\n",
    "\tfor i in range(8):\n",
    "\t\tnext_token, done_vec, state = decoder.generate_next_token(test_encoded_context[:3, :, :], next_token, done_vec, state)\n",
    "\t\ttokens.append(next_token)\n",
    "\t\n",
    "\t# Merge all batch outputs into a single dimension\n",
    "\ttokens = tf.concat(tokens, -1) # -1 = last axis\n",
    "\n",
    "\tprint('Output:', decoder.tokens_to_text(tokens).numpy())\n",
    "\n",
    "test_generation_loop()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17c3411a",
   "metadata": {},
   "source": [
    "## The model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "116b3a40",
   "metadata": {},
   "source": [
    "We can now build a model for training and punctuation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1520bd75",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Punctuator(tf.keras.Model):\n",
    "\tdef __init__(self, units, context_text_processor, target_text_processor):\n",
    "\t\tsuper().__init__()\n",
    "\t\tself.encoder = Encoder(context_text_processor, units)\n",
    "\t\tself.decoder = Decoder(target_text_processor, units)\n",
    "\t\n",
    "\tdef call(self, inputs):\n",
    "\t\tcontext, target_history = inputs\n",
    "\t\tcontext = self.encoder(context)\n",
    "\t\tlogits = self.decoder(context, target_history)\n",
    "\t\treturn logits\n",
    "\t\n",
    "\tdef fix_punctuation_raw(self, input):\n",
    "\t\t\"\"\"\n",
    "\t\tAdds punctuation to `input`, where `input` is a `Tensor` with shape (batch_size, s) where s is the\n",
    "\t\tcontext length.\n",
    "\t\t\"\"\"\n",
    "\t\tcontext = self.encoder(input)\n",
    "\n",
    "\t\tnext_token, done_vec, state = self.decoder.get_initial_state(context)\n",
    "\n",
    "\t\t# Although a TensorArray would allow more efficient exporting, the ONNX exporter seems to\n",
    "\t\t# have trouble with it. For now, use a Python list.\n",
    "\t\ttokens = []\n",
    "\t\tmax_iterations = 34\n",
    "\n",
    "\t\tfor i in range(max_iterations):\n",
    "\t\t\t# token_history has size: (batch, t, target_vocab_size)\n",
    "\t\t\t# token_history = tf.concat(tokens, 1)\n",
    "\t\t\t# print('history', model.decoder.id_to_word(token_history))\n",
    "\t\t\tnext_token, done_vec, state = self.decoder.generate_next_token(context, next_token, done_vec, state, temperature=0)\n",
    "\t\t\t#tokens = tokens.write(i + 1, next_token)\n",
    "\t\t\ttokens.append(next_token)\n",
    "\n",
    "\t\t\tif tf.executing_eagerly() and tf.reduce_all(done_vec):\n",
    "\t\t\t\tbreak\n",
    "\t\t\n",
    "\t\ttokens = tf.concat(tokens, -1)\n",
    "\t\t# When exporting to ONNX, tokens_to_text can only operate on a single dimension. As such,\n",
    "\t\t# all inputs are collapsed:\n",
    "\t\treturn tokens\n",
    "\n",
    "\tdef fix_punctuation(self, text: list[str]):\n",
    "\t\tinputs = self.encoder.prepare_for_input(text)\n",
    "\t\ttokens = self.fix_punctuation_raw(inputs)\n",
    "\t\treturn self.decoder.tokens_to_text(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "253c670d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Context tokens shape (batch, s): (16, 52)\n",
      "Target history tokens shape (batch, t): (16, 69)\n",
      "Logits shape (batch, t, vocab_size) (16, 69, 2000)\n"
     ]
    }
   ],
   "source": [
    "model = Punctuator(ENCODER_UNITS, context_text_processor, target_text_processor)\n",
    "\n",
    "for (example_context_tok, example_target_hist), _ in dataset_validate.take(1):\n",
    "\ttest_logits = model((example_context_tok, example_target_hist))\n",
    "\tprint('Context tokens shape (batch, s):', example_context_tok.shape)\n",
    "\tprint('Target history tokens shape (batch, t):', example_target_hist.shape)\n",
    "\tprint('Logits shape (batch, t, vocab_size)', test_logits.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "68e81b32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"punctuator\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"punctuator\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ encoder_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Encoder</span>)             │ ?                      │       <span style=\"color: #00af00; text-decoration-color: #00af00\">124,224</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ decoder_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Decoder</span>)             │ ?                      │       <span style=\"color: #00af00; text-decoration-color: #00af00\">217,616</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ encoder_1 (\u001b[38;5;33mEncoder\u001b[0m)             │ ?                      │       \u001b[38;5;34m124,224\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ decoder_1 (\u001b[38;5;33mDecoder\u001b[0m)             │ ?                      │       \u001b[38;5;34m217,616\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">341,840</span> (1.30 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m341,840\u001b[0m (1.30 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">341,840</span> (1.30 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m341,840\u001b[0m (1.30 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85551c17",
   "metadata": {},
   "source": [
    "To avoid penalizing masked outputs, we use a custom loss function (see the tutorial):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6ca4d983",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True, reduction='none')\n",
    "\n",
    "def masked_loss(y_true, y_predict):\n",
    "\tloss = base_loss_fn(y_true, y_predict)\n",
    "\t\n",
    "\tunmasked = y_true != 0\n",
    "\tunmasked = tf.cast(unmasked, loss.dtype)\n",
    "\t# Only consider output with a corresponding label.\n",
    "\tloss *= unmasked\n",
    "\n",
    "\tcount_unmasked = tf.math.reduce_sum(unmasked)\n",
    "\n",
    "\t# reduce_sum: Adds all entries of a vector.\n",
    "\treturn tf.math.reduce_sum(loss)/count_unmasked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4ba83b38",
   "metadata": {},
   "outputs": [],
   "source": [
    "def masked_accuracy(y_true, predict_logits):\n",
    "\tpredicted_index = tf.math.argmax(predict_logits, axis=-1)\n",
    "\tpredicted_index = tf.cast(predicted_index, y_true.dtype)\n",
    "\n",
    "\tmatch = tf.cast(y_true == predicted_index, tf.float32)\n",
    "\tunmasked = tf.cast(y_true != 0, tf.float32)\n",
    "\tcount_unmasked = tf.math.reduce_sum(unmasked)\n",
    "\n",
    "\treturn tf.math.reduce_sum(match * unmasked) / count_unmasked\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5d9fde0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.compile(optimizer='adam', loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True), metrics=[masked_accuracy, masked_loss])\n",
    "model.compile(optimizer='adam', loss=masked_loss, metrics=[masked_accuracy, masked_loss])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "95ae7f1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "From the tutorial:\n",
      "expected loss 7.6009026\n",
      "expected accuracy 0.0005\n"
     ]
    }
   ],
   "source": [
    "print('From the tutorial:')\n",
    "vocab_size = float(target_text_processor.vocabulary_size())\n",
    "\n",
    "print('expected loss', tf.math.log(vocab_size).numpy())\n",
    "print('expected accuracy', 1/vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "091b83b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 33ms/step - loss: 7.6039 - masked_accuracy: 1.0857e-04 - masked_loss: 7.6039\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'loss': 7.603926658630371,\n",
       " 'masked_accuracy': 0.00015984181663952768,\n",
       " 'masked_loss': 7.6039276123046875}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(dataset_validate, steps=20, return_dict=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a179e6b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[test]: sensation dressed feelings drive dressed feelings curious express promised sympathy breast grey sister presence lion wore mystery smoke dim hungry treasure terror bring pleasant pleasant pleasant repeat carrying play misfortune inside wild facts monte'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "def test_punctuation(text):\n",
    "\treturn '[test]: ' + model.fix_punctuation(text).numpy().decode('utf-8')\n",
    "\n",
    "class DemoCallback(tf.keras.callbacks.Callback):\n",
    "\tdef on_epoch_end(self, epoch_index: int, logs = None):\n",
    "\t\tprint('\\r', test_punctuation([ 'test this is a sample will it work if it does then how well' ]))\n",
    "\t\tif epoch_index % 10 == 0:\n",
    "\t\t\t# From the test data\n",
    "\t\t\tprint(test_punctuation([\n",
    "\t\t\t\t'not that alice had any idea of doing that she felt as if she would never be able to talk again, she was getting so much out of breath and still the queen cried faster faster and dragged her along'\n",
    "\t\t\t]))\n",
    "\t\t\tprint(test_punctuation([ 'tensorflow is a library that is used for machine learning it is available for more languages than just python' ]))\n",
    "\t\t\tprint(test_punctuation([ 'the joplin note taking app can be used to take multimedia notes' ]))\n",
    "\t\t\tprint(test_punctuation([ 'here are a few words javascript typescript python joplin interesting loud and sequence these words are all very useful' ]))\n",
    "\n",
    "test_punctuation(tf.constant([ 'this is an example they said' ]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a2db06e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "\u001b[1m499/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - loss: 5.2544 - masked_accuracy: 0.1673 - masked_loss: 5.2544"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib64/python3.11/contextlib.py:158: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
      "  self.gen.throw(typ, value, traceback)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [test]: [cap] i have not [UNK] , and [cap] i have [UNK] , and [cap] i have [UNK] , and [cap] i have [UNK] , and [cap] i have [UNK] , and [cap] i have\n",
      "[test]: [cap] i had [UNK] to [UNK] .\n",
      "[test]: [cap] i [UNK] [UNK] , and [UNK] [UNK] , and [UNK] [UNK] , and [UNK] [UNK] , and [UNK] [UNK] , and [UNK] [UNK] , and [UNK] [UNK] , and [UNK] [UNK] , and\n",
      "[test]: [cap] [UNK] , [cap] i have been [UNK] to [UNK] .\n",
      "[test]: [cap] [UNK] , and [UNK] [UNK] , and [UNK] [UNK] , and [UNK] [UNK] , and [UNK] [UNK] , and [UNK] [UNK] , and [UNK] [UNK] , and [UNK] [UNK] , and [UNK] [UNK]\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 82ms/step - loss: 5.2516 - masked_accuracy: 0.1676 - masked_loss: 5.2516 - val_loss: 3.9222 - val_masked_accuracy: 0.2783 - val_masked_loss: 3.8619\n",
      "Epoch 2/30\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - loss: 3.7639 - masked_accuracy: 0.3097 - masked_loss: 3.7639"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-05 19:34:35.454265: I tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node IteratorGetNext}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [test]: [cap] [UNK] this is a [UNK] , and it , it as it it is it ?\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 66ms/step - loss: 3.7634 - masked_accuracy: 0.3098 - masked_loss: 3.7634 - val_loss: 2.7005 - val_masked_accuracy: 0.4905 - val_masked_loss: 2.6590\n",
      "Epoch 3/30\n",
      " [test]: [cap] [UNK] this is a [UNK] will be work , if it does then how well .loss: 2.4612 - masked_accuracy: 0.5349 - masked_loss: 2.4612\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 64ms/step - loss: 2.4607 - masked_accuracy: 0.5350 - masked_loss: 2.4607 - val_loss: 1.7115 - val_masked_accuracy: 0.6387 - val_masked_loss: 1.6852\n",
      "Epoch 4/30\n",
      " [test]: [cap] [UNK] this is a [UNK] will it work if it does then how well .- loss: 1.5722 - masked_accuracy: 0.6764 - masked_loss: 1.5722\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 67ms/step - loss: 1.5719 - masked_accuracy: 0.6765 - masked_loss: 1.5719 - val_loss: 1.1549 - val_masked_accuracy: 0.7292 - val_masked_loss: 1.1372\n",
      "Epoch 5/30\n",
      " [test]: [cap] [UNK] this is a [UNK] will it work if it does then how well .- loss: 1.0798 - masked_accuracy: 0.7616 - masked_loss: 1.0798\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 64ms/step - loss: 1.0796 - masked_accuracy: 0.7616 - masked_loss: 1.0796 - val_loss: 0.8292 - val_masked_accuracy: 0.7944 - val_masked_loss: 0.8165\n",
      "Epoch 6/30\n",
      " [test]: [cap] [UNK] this is a [UNK] will it work if it does then how well .- loss: 0.8322 - masked_accuracy: 0.8069 - masked_loss: 0.8322\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 68ms/step - loss: 0.8321 - masked_accuracy: 0.8069 - masked_loss: 0.8321 - val_loss: 0.6131 - val_masked_accuracy: 0.8377 - val_masked_loss: 0.6037\n",
      "Epoch 7/30\n",
      " [test]: [cap] [UNK] this is a [UNK] will it work , if it does then ? [cap] how well .6542 - masked_accuracy: 0.8407 - masked_loss: 0.6542\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 64ms/step - loss: 0.6542 - masked_accuracy: 0.8407 - masked_loss: 0.6542 - val_loss: 0.5867 - val_masked_accuracy: 0.8402 - val_masked_loss: 0.5777\n",
      "Epoch 8/30\n",
      " [test]: [cap] [UNK] this is a [UNK] will it work , if it does then , how well .ss: 0.6327 - masked_accuracy: 0.8417 - masked_loss: 0.6327\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 70ms/step - loss: 0.6327 - masked_accuracy: 0.8417 - masked_loss: 0.6327 - val_loss: 0.5407 - val_masked_accuracy: 0.8462 - val_masked_loss: 0.5323\n",
      "Epoch 9/30\n",
      " [test]: [cap] [UNK] this is a [UNK] will it work , if it does then ? [cap] how well .5944 - masked_accuracy: 0.8483 - masked_loss: 0.5944\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 73ms/step - loss: 0.5943 - masked_accuracy: 0.8483 - masked_loss: 0.5943 - val_loss: 0.5204 - val_masked_accuracy: 0.8486 - val_masked_loss: 0.5124\n",
      "Epoch 10/30\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - loss: 0.5593 - masked_accuracy: 0.8557 - masked_loss: 0.5593"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-05 19:39:03.046974: I tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node IteratorGetNext}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [test]: [cap] [UNK] this is a [UNK] will it work if it does then , how well .\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 65ms/step - loss: 0.5594 - masked_accuracy: 0.8557 - masked_loss: 0.5594 - val_loss: 0.6103 - val_masked_accuracy: 0.8311 - val_masked_loss: 0.6009\n",
      "Epoch 11/30\n",
      " [test]: [cap] [UNK] this is a [UNK] will it work , if it does then , how well .ss: 0.5363 - masked_accuracy: 0.8595 - masked_loss: 0.5363\n",
      "[test]: [cap] not that [cap] alice had any idea of doing that she felt as if she would never be able to talk again . [cap] she was getting , she so much out of\n",
      "[test]: [cap] [UNK] is a library , that is used for [UNK] [UNK] it is [UNK] for more [UNK] than just [UNK] .\n",
      "[test]: [cap] the [UNK] note , taking [UNK] can be used to take [UNK] notes .\n",
      "[test]: [cap] here are a few words [UNK] [UNK] [UNK] [UNK] interesting loud and [UNK] these words are all very [UNK] .\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 70ms/step - loss: 0.5364 - masked_accuracy: 0.8595 - masked_loss: 0.5364 - val_loss: 0.4999 - val_masked_accuracy: 0.8517 - val_masked_loss: 0.4922\n",
      "Epoch 12/30\n",
      " [test]: [cap] [UNK] this is a [UNK] will it work , if it does then how well .loss: 0.5256 - masked_accuracy: 0.8625 - masked_loss: 0.5256\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 72ms/step - loss: 0.5256 - masked_accuracy: 0.8625 - masked_loss: 0.5256 - val_loss: 0.5339 - val_masked_accuracy: 0.8488 - val_masked_loss: 0.5257\n",
      "Epoch 13/30\n",
      " [test]: [cap] [UNK] . [cap] this is a [UNK] will it work , if it does ? [cap] how how well .masked_accuracy: 0.8674 - masked_loss: 0.4943\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 67ms/step - loss: 0.4943 - masked_accuracy: 0.8674 - masked_loss: 0.4943 - val_loss: 0.4811 - val_masked_accuracy: 0.8564 - val_masked_loss: 0.4737\n",
      "Epoch 14/30\n",
      " [test]: [cap] [UNK] this is a [UNK] will it work , if it does then how well .loss: 0.4994 - masked_accuracy: 0.8660 - masked_loss: 0.4994\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 67ms/step - loss: 0.4993 - masked_accuracy: 0.8660 - masked_loss: 0.4993 - val_loss: 0.4627 - val_masked_accuracy: 0.8614 - val_masked_loss: 0.4556\n",
      "Epoch 15/30\n",
      " [test]: [cap] [UNK] this is a [UNK] will it work , if it does then ? [cap] how well .4984 - masked_accuracy: 0.8656 - masked_loss: 0.4984\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 68ms/step - loss: 0.4984 - masked_accuracy: 0.8656 - masked_loss: 0.4984 - val_loss: 0.4937 - val_masked_accuracy: 0.8515 - val_masked_loss: 0.4861\n",
      "Epoch 16/30\n",
      " [test]: [cap] [UNK] , this is a [UNK] will it work if it does then ? [cap] how well .4992 - masked_accuracy: 0.8676 - masked_loss: 0.4992\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 65ms/step - loss: 0.4993 - masked_accuracy: 0.8675 - masked_loss: 0.4993 - val_loss: 0.4603 - val_masked_accuracy: 0.8634 - val_masked_loss: 0.4532\n",
      "Epoch 17/30\n",
      " [test]: [cap] [UNK] this is a [UNK] will it work , if it does then how well ?loss: 0.4593 - masked_accuracy: 0.8741 - masked_loss: 0.4593\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 70ms/step - loss: 0.4594 - masked_accuracy: 0.8741 - masked_loss: 0.4594 - val_loss: 0.5269 - val_masked_accuracy: 0.8484 - val_masked_loss: 0.5188\n",
      "Epoch 18/30\n",
      " [test]: [cap] [UNK] . [cap] this is a [UNK] will it work if it does then how well ?0.4871 - masked_accuracy: 0.8692 - masked_loss: 0.4871\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 73ms/step - loss: 0.4871 - masked_accuracy: 0.8692 - masked_loss: 0.4870 - val_loss: 0.4096 - val_masked_accuracy: 0.8681 - val_masked_loss: 0.4033\n",
      "Epoch 19/30\n",
      " [test]: [cap] [UNK] . [cap] this is a [UNK] will it work if it does then how well ?0.4454 - masked_accuracy: 0.8769 - masked_loss: 0.4454\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 65ms/step - loss: 0.4454 - masked_accuracy: 0.8769 - masked_loss: 0.4454 - val_loss: 0.4501 - val_masked_accuracy: 0.8615 - val_masked_loss: 0.4431\n",
      "Epoch 20/30\n",
      " [test]: [cap] [UNK] . [cap] this is a [UNK] will it work , if it does then , how well ?17 - masked_accuracy: 0.8773 - masked_loss: 0.4417\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 68ms/step - loss: 0.4416 - masked_accuracy: 0.8773 - masked_loss: 0.4416 - val_loss: 0.4097 - val_masked_accuracy: 0.8698 - val_masked_loss: 0.4034\n",
      "Epoch 21/30\n",
      " [test]: [cap] [UNK] this is a [UNK] will it work , if it does then ? [cap] how well ?4321 - masked_accuracy: 0.8796 - masked_loss: 0.4321\n",
      "[test]: [cap] not that [cap] alice had any idea of doing that she felt as if she would never be able to talk again . [cap] she was getting so much out of breath ,\n",
      "[test]: [cap] [UNK] is a library that is used for [UNK] [UNK] it is [UNK] for more [UNK] than just [UNK] .\n",
      "[test]: [cap] the [UNK] note , taking [UNK] can be used to take [UNK] notes .\n",
      "[test]: [cap] here are a few words [UNK] [UNK] [UNK] [UNK] interesting loud and [UNK] these words are all very [UNK] .\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 70ms/step - loss: 0.4321 - masked_accuracy: 0.8796 - masked_loss: 0.4321 - val_loss: 0.4045 - val_masked_accuracy: 0.8731 - val_masked_loss: 0.3983\n",
      "Epoch 22/30\n",
      " [test]: [cap] [UNK] . [cap] this is a [UNK] will it work , if it does then how well ?4312 - masked_accuracy: 0.8798 - masked_loss: 0.4312\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 68ms/step - loss: 0.4312 - masked_accuracy: 0.8798 - masked_loss: 0.4312 - val_loss: 0.3938 - val_masked_accuracy: 0.8743 - val_masked_loss: 0.3877\n",
      "Epoch 23/30\n",
      " [test]: [cap] [UNK] this is a [UNK] will it work , if it does then ? [cap] how well ?4331 - masked_accuracy: 0.8800 - masked_loss: 0.4331\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 71ms/step - loss: 0.4331 - masked_accuracy: 0.8800 - masked_loss: 0.4331 - val_loss: 0.4242 - val_masked_accuracy: 0.8688 - val_masked_loss: 0.4176\n",
      "Epoch 24/30\n",
      " [test]: [cap] [UNK] this is a [UNK] will it work , if it does then , how well ?ss: 0.4110 - masked_accuracy: 0.8829 - masked_loss: 0.4110\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 80ms/step - loss: 0.4110 - masked_accuracy: 0.8829 - masked_loss: 0.4110 - val_loss: 0.4474 - val_masked_accuracy: 0.8621 - val_masked_loss: 0.4405\n",
      "Epoch 25/30\n",
      " [test]: [cap] [UNK] this is a [UNK] will it work , if it does then how well ?loss: 0.4286 - masked_accuracy: 0.8803 - masked_loss: 0.4286\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 77ms/step - loss: 0.4286 - masked_accuracy: 0.8803 - masked_loss: 0.4286 - val_loss: 0.4004 - val_masked_accuracy: 0.8738 - val_masked_loss: 0.3942\n",
      "Epoch 26/30\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - loss: 0.4023 - masked_accuracy: 0.8844 - masked_loss: 0.4023"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-05 19:48:27.759985: I tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node IteratorGetNext}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [test]: [cap] [UNK] this is a [UNK] will it work , if it does then how well ?\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 77ms/step - loss: 0.4023 - masked_accuracy: 0.8844 - masked_loss: 0.4023 - val_loss: 0.3833 - val_masked_accuracy: 0.8730 - val_masked_loss: 0.3774\n",
      "Epoch 27/30\n",
      " [test]: [cap] [UNK] , this is a [UNK] will it work , if it does then how well ?ss: 0.4390 - masked_accuracy: 0.8784 - masked_loss: 0.4390\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 78ms/step - loss: 0.4390 - masked_accuracy: 0.8784 - masked_loss: 0.4390 - val_loss: 0.4142 - val_masked_accuracy: 0.8667 - val_masked_loss: 0.4078\n",
      "Epoch 28/30\n",
      " [test]: [cap] [UNK] this is a [UNK] will it work , if it does then how well ?loss: 0.4243 - masked_accuracy: 0.8811 - masked_loss: 0.4243\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 80ms/step - loss: 0.4243 - masked_accuracy: 0.8811 - masked_loss: 0.4243 - val_loss: 0.3983 - val_masked_accuracy: 0.8730 - val_masked_loss: 0.3921\n",
      "Epoch 29/30\n",
      " [test]: [cap] [UNK] this is a [UNK] will it work , if it does then how well ?loss: 0.4145 - masked_accuracy: 0.8835 - masked_loss: 0.4145\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 79ms/step - loss: 0.4145 - masked_accuracy: 0.8835 - masked_loss: 0.4145 - val_loss: 0.3826 - val_masked_accuracy: 0.8757 - val_masked_loss: 0.3767\n",
      "Epoch 30/30\n",
      " [test]: [cap] [UNK] this is a [UNK] will it work , if it does then how well ?loss: 0.4134 - masked_accuracy: 0.8829 - masked_loss: 0.4134\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 83ms/step - loss: 0.4134 - masked_accuracy: 0.8829 - masked_loss: 0.4134 - val_loss: 0.3943 - val_masked_accuracy: 0.8749 - val_masked_loss: 0.3882\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "\tdataset_train,\n",
    "\tepochs = 30,\n",
    "\tsteps_per_epoch = 500,\n",
    "\tvalidation_data = dataset_validate,\n",
    "\tcallbacks=[DemoCallback()]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f68a9fba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[test]: [cap] not that [cap] alice had any idea of doing that she felt as if she would never be able to talk again she was getting so much out of breath , and still\n",
      "[test]: [cap] this is a [UNK] of a the [UNK] [UNK] for [cap] i am curious how well it [UNK] .\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(test_punctuation([\n",
    "\t'not that alice had any idea of doing that she felt as if she would never be able to talk again she was getting so much out of breath and still the queen cried faster faster and dragged her along'\n",
    "]))\n",
    "print(test_punctuation([ 'this is a test of a the punctuation system for i am curious how well it works' ]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b1e9cc9",
   "metadata": {},
   "source": [
    "## Exporting\n",
    "\n",
    "Based on the [Export](https://www.tensorflow.org/text/tutorials/nmt_with_attention#export) section of the tutorial:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "e9885c66",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Export(tf.Module):\n",
    "\tdef __init__(self, model):\n",
    "\t\tself.model = model\n",
    "\t\n",
    "\t@tf.function(input_signature=[tf.RaggedTensorSpec(dtype=tf.int64, shape=[None])])\n",
    "\tdef fix_punctuation(self, input):\n",
    "\t\treturn model.fix_punctuation_raw(\n",
    "\t\t\ttf.reshape(input, [1, -1])\n",
    "\t\t)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42bcac14",
   "metadata": {},
   "source": [
    "Run `fix_punctuation` once to compile it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "fa037d66",
   "metadata": {},
   "outputs": [],
   "source": [
    "export = Export(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "8af27599",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=string, numpy=b'[cap] this sentence shall be [UNK] for the following reasons first [UNK] makes things [UNK] to read second [UNK] .'>"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_inputs = context_text_processor('this sentence shall be punctuated for the following reasons first punctatuion makes things easier to read second um')\n",
    "model.decoder.tokens_to_text(export.fix_punctuation(sample_inputs))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70247292",
   "metadata": {},
   "source": [
    "Now we save the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "badb8d86",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/self/Documents/punctuation-fixer/env/lib64/python3.11/site-packages/keras/src/layers/layer.py:934: UserWarning: Layer 'query' (of type EinsumDense) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
      "  warnings.warn(\n",
      "/home/self/Documents/punctuation-fixer/env/lib64/python3.11/site-packages/keras/src/layers/layer.py:934: UserWarning: Layer 'key' (of type EinsumDense) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
      "  warnings.warn(\n",
      "/home/self/Documents/punctuation-fixer/env/lib64/python3.11/site-packages/keras/src/layers/layer.py:934: UserWarning: Layer 'value' (of type EinsumDense) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
      "  warnings.warn(\n",
      "/home/self/Documents/punctuation-fixer/env/lib64/python3.11/site-packages/keras/src/layers/layer.py:934: UserWarning: Layer 'query' (of type EinsumDense) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
      "  warnings.warn(\n",
      "/home/self/Documents/punctuation-fixer/env/lib64/python3.11/site-packages/keras/src/layers/layer.py:934: UserWarning: Layer 'key' (of type EinsumDense) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
      "  warnings.warn(\n",
      "/home/self/Documents/punctuation-fixer/env/lib64/python3.11/site-packages/keras/src/layers/layer.py:934: UserWarning: Layer 'value' (of type EinsumDense) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: punctuator-seq2seq/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: punctuator-seq2seq/assets\n"
     ]
    }
   ],
   "source": [
    "tf.saved_model.save(export, 'punctuator-seq2seq', signatures={ 'serving_default': export.fix_punctuation })"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "197976b4",
   "metadata": {},
   "source": [
    "See [the documentation](https://www.tensorflow.org/guide/saved_model#specifying_signatures_during_export) for information about the `signatures` option."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "56d91fbf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19729"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "web_output_dir = Path('web')\n",
    "vocab_output_file = web_output_dir / 'wordEncodings.ts'\n",
    "\n",
    "vocab_output_file.write_text('''\n",
    "// Auto-generated file!\n",
    "// Created by v2-seq2seq.ipynb\n",
    "export default {};\n",
    "'''.format(json.dumps(target_text_processor.get_vocabulary())))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29d873f2",
   "metadata": {},
   "source": [
    "### Testing the saved model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "c39fbc2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imported and warmed up!\n"
     ]
    }
   ],
   "source": [
    "reloaded = tf.saved_model.load('punctuator-seq2seq')\n",
    "# Warmup\n",
    "reloaded.fix_punctuation(sample_inputs)\n",
    "print('Imported and warmed up!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "ca974c8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 41.1 ms, sys: 15.7 ms, total: 56.8 ms\n",
      "Wall time: 24.3 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=string, numpy=b'[cap] this sentence shall be [UNK] for the following reasons first [UNK] makes things [UNK] to read second [UNK] .'>"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "model.decoder.tokens_to_text(reloaded.fix_punctuation(sample_inputs))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afb2771e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
