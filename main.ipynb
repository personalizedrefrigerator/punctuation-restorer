{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "71899cc9-86b4-4eda-b525-d818661c70a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-31 15:58:11.970512: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-08-31 15:58:11.977465: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-08-31 15:58:11.986886: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-08-31 15:58:12.005478: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-08-31 15:58:12.010049: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-08-31 15:58:12.021188: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-08-31 15:58:12.866446: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa459db2-5a48-4bac-8cbd-38496888faee",
   "metadata": {},
   "source": [
    "**Notes**:\n",
    "- This notebook follows [an online tutorial](https://www.tensorflow.org/text/tutorials/nmt_with_attention) (and [at least one other](https://www.tensorflow.org/text/tutorials/text_generation) of the Tensorflow tutorials).\n",
    "- This [blog post](https://janakiev.com/blog/jupyter-virtual-envs/) was referenced to set up the virtual environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "92b150ba-48c0-4f33-8d08-b9f363d6fcfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import typing\n",
    "from typing import Any, Tuple\n",
    "from prepare_data import load_data, reconstruct_from_labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5faca0eb-c672-4d1c-884f-b5ba38a22b63",
   "metadata": {},
   "outputs": [],
   "source": [
    "context_raw, target_raw = load_data('./data/en/')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5890fa88",
   "metadata": {},
   "source": [
    "We store the **expected** output in `target_raw` and the input to our model in `context_raw`. Let's see an example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7bbcb7c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['0', 'x'],\n",
       "       ['1', 'x'],\n",
       "       ['0', 'x'],\n",
       "       ...,\n",
       "       ['1', 'x'],\n",
       "       ['0', 'x'],\n",
       "       ['0', 'x']], dtype='<U21')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_raw"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab821739",
   "metadata": {},
   "source": [
    "Each element in `target_raw` is an operation (e.g. 0 = copy) followed by a character code. For example, `1` is \"capitalize\" and `0` is \"copy\". Note that `120` (`ord(x)`) is used for operations that take no arguments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "55ea3dde",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array(['0', 'x'], dtype='<U21'), 'v')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_raw[24], context_raw[24]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64f129de",
   "metadata": {},
   "source": [
    "\n",
    "## Creating a dataset\n",
    "\n",
    "We begin by vectorizing our data. `target_raw` and `context_raw` are already tokenized by characters/operations.\n",
    "\n",
    "We start by creating a vectorization for the `target_raw`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2e2805cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input vocab size in chars: 54\n"
     ]
    }
   ],
   "source": [
    "input_vocab = sorted(set(context_raw))\n",
    "print('Input vocab size in chars:', len(input_vocab))\n",
    "\n",
    "chars_to_ids_in = tf.keras.layers.StringLookup(vocabulary=input_vocab)\n",
    "# Invert: Map chars to IDs instead of IDs to chars\n",
    "ids_to_chars_in = tf.keras.layers.StringLookup(vocabulary=chars_to_ids_in.get_vocabulary(), invert=True)\n",
    "\n",
    "# in: \"Input\"\n",
    "def text_from_ids_in(ids: list[int]):\n",
    "\treturn tf.strings.reduce_join(ids_to_chars_in(ids), axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "99fc264b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(6213260,), dtype=int64, numpy=array([40, 22, 25, ..., 31, 13,  1])>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_ids_input = chars_to_ids_in(context_raw)\n",
    "all_ids_input"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "116b3a40",
   "metadata": {},
   "source": [
    "Now, we do the same for the output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1520bd75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output vocab size in chars: 8\n"
     ]
    }
   ],
   "source": [
    "output_vocab = sorted(set(target_raw[:, 1]))\n",
    "print('Output vocab size in chars:', len(output_vocab))\n",
    "\n",
    "chars_to_ids_out = tf.keras.layers.StringLookup(vocabulary=output_vocab)\n",
    "# Invert: Map chars to IDs instead of IDs to chars\n",
    "ids_to_chars_out = tf.keras.layers.StringLookup(vocabulary=chars_to_ids_out.get_vocabulary(), invert=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4ba83b38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['!', \"'\", ',', '-', '.', '/', '?', 'x']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(set(target_raw[:,1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5d9fde0a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(6213260,), dtype=int64, numpy=array([8, 8, 8, ..., 8, 8, 8])>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_ids_output = chars_to_ids_out(target_raw[:, 1])\n",
    "all_ids_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8fd7b5bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 0, ..., 1, 0, 0])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_commands_output = np.array(list(map(int, target_raw[:, 0])))\n",
    "all_commands_output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af035816",
   "metadata": {},
   "source": [
    "Now that we have vectorized inputs and outputs, let's create a `Dataset` we can feed to the model.\n",
    "\n",
    "First, combine the expected inputs and outputs into a single vector:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e2e72752",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(6213260, 3), dtype=int64, numpy=\n",
       "array([[40,  0,  8],\n",
       "       [22,  1,  8],\n",
       "       [25,  0,  8],\n",
       "       ...,\n",
       "       [31,  1,  8],\n",
       "       [13,  0,  8],\n",
       "       [ 1,  0,  8]])>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def column(v):\n",
    "\treturn tf.reshape(v, [-1, 1])\n",
    "\n",
    "ids_and_outputs = tf.concat([\n",
    "\tcolumn(all_ids_input), column(all_commands_output), column(all_ids_output)\n",
    "], 1)\n",
    "ids_and_outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e45b3dd",
   "metadata": {},
   "source": [
    "Next, create a `Dataset`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9f1626f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "~ c(0, x), i c(1, x), l c(0, x), l c(0, x), u c(0, x), s c(0, x), t c(0, x), r c(0, x), a c(0, x), t c(0, x), i c(0, x), o c(0, x), n c(0, x),   c(0, x), ~ c(0, x), a c(1, x), l c(0, x), i c(0, x), c c(0, x), e c(0, x), s c(2, '),   c(0, x), a c(1, x), d c(0, x), v c(0, x), e c(0, x), n c(0, x), t c(0, x), u c(0, x), r c(0, x), e c(0, x), s c(0, x), "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-31 15:58:29.233928: I tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    }
   ],
   "source": [
    "# Separates ids_and_outputs along its first dimension into different items in the dataset.\n",
    "ids_input_dataset = tf.data.Dataset.from_tensor_slices(all_ids_input)\n",
    "# Tuples: from_tensor_slices pairs entries of each tuple item to produce the dataset.\n",
    "output_dataset = tf.data.Dataset.from_tensor_slices((all_commands_output, all_ids_output))\n",
    "dataset = tf.data.Dataset.zip(ids_input_dataset, output_dataset)\n",
    "\n",
    "# Preview the dataset -- demonstrates converting Tensors to numpy to text\n",
    "for input, expected_sample_outputs in dataset.take(32):\n",
    "\tcmd_output, arg_output = expected_sample_outputs\n",
    "\tinput_char = ids_to_chars_in(input).numpy().decode('utf-8')\n",
    "\tcommand = cmd_output.numpy()\n",
    "\tcommand_arg = ids_to_chars_out(arg_output).numpy().decode('utf-8')\n",
    "\n",
    "\tprint('{} c({}, {})'.format(input_char, command, command_arg), end = ', ')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dfe60be9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inputs: tf.Tensor(b'~illustration ~alices adventures in wonderland ~by lewis carroll ~the millennium ', shape=(), dtype=string)\n",
      "Inputs: tf.Tensor(b'fulcrum edition 30 ~contents ~chapter i down the rabbithole chapter ii the pool o', shape=(), dtype=string)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-31 15:58:29.294968: I tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    }
   ],
   "source": [
    "seq_length = 80\n",
    "\n",
    "# batch: Convert the dataset to sequences of the target size.\n",
    "# drop_remainder: Drop the last batch if it has fewer than 80 elements\n",
    "sequences = dataset.batch(seq_length + 1, drop_remainder=True)\n",
    "\n",
    "for sample_inputs, expected_sample_outputs in sequences.take(2):\n",
    "\tprint('Inputs:', text_from_ids_in(sample_inputs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "30c9b190",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = sequences"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7db7917f",
   "metadata": {},
   "source": [
    "Our dataset now pairs inputs and labels!\n",
    "\n",
    "**Note**: This [StackOverflow](https://stackoverflow.com/questions/53171885/how-to-use-tf-data-dataset-and-tf-keras-do-multi-inputs-and-multi-outpus) question, the documentation on [Dataset.zip](https://www.tensorflow.org/api_docs/python/tf/data/Dataset?hl=en#zip), and documentation on [Dataset.from_tensor_slices](https://www.tensorflow.org/api_docs/python/tf/data/Dataset?hl=en#from_tensor_slices) were helpful."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0854f4b3",
   "metadata": {},
   "source": [
    "## Final preprocessing\n",
    "\n",
    "We now shuffle the data, then do final batching."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a50a19ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "BUFFER_SIZE = 10000\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "dataset = dataset.shuffle(BUFFER_SIZE).batch(BATCH_SIZE, drop_remainder = True).prefetch(tf.data.AUTOTUNE)\n",
    "# Break into test and training data (no validation data for now).\n",
    "# Inspired by https://stackoverflow.com/a/74609848.\n",
    "validate_size = dataset.cardinality() * 1 // 8\n",
    "dataset_validate = dataset.take(validate_size)\n",
    "dataset = dataset.skip(validate_size)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ed3f818",
   "metadata": {},
   "source": [
    "## Building the model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b47b9620",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vocab_size_in 55\n",
      "vocab_size_out 9\n",
      "command_count 3\n",
      "EMBEDDING_DIM 32\n",
      "RNN_UNITS 128\n"
     ]
    }
   ],
   "source": [
    "# .get_vocabulary: Returns a list of the characters in use.\n",
    "vocab_size_in = len(chars_to_ids_in.get_vocabulary())\n",
    "\n",
    "vocab_size_out = len(chars_to_ids_out.get_vocabulary())\n",
    "command_count = len(set(all_commands_output))\n",
    "size_out = command_count + vocab_size_out # Output includes both commands and the command arg\n",
    "\n",
    "EMBEDDING_DIM = 64\n",
    "RNN_UNITS = 64 # Dimensionality of GRU output\n",
    "\n",
    "print('vocab_size_in', vocab_size_in)\n",
    "print('vocab_size_out', vocab_size_out)\n",
    "print('command_count', command_count)\n",
    "print('EMBEDDING_DIM', EMBEDDING_DIM)\n",
    "print('RNN_UNITS', RNN_UNITS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6287f97c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LanguageModel(tf.keras.Model):\n",
    "\tdef __init__(self):\n",
    "\t\tsuper().__init__()\n",
    "\n",
    "\t\tself.embedding_layer = tf.keras.layers.Embedding(vocab_size_in, EMBEDDING_DIM)\n",
    "\t\t# return_sequences: Return the full sequence of outputs, rather than just the last.\n",
    "\t\t# return_state: Returns the last state in addition to the output\n",
    "\t\tself.gru_layer = tf.keras.layers.GRU(RNN_UNITS, return_sequences=True, return_state=True)\n",
    "\t\tself.dense_command_layer = tf.keras.layers.Dense(command_count, activation=tf.keras.activations.log_softmax)\n",
    "\t\tself.dense_arg_layer = tf.keras.layers.Dense(vocab_size_out, activation=tf.keras.activations.log_softmax)\n",
    "\t\n",
    "\tdef call(self, inputs, states = None, return_state = False, training = False):\n",
    "\t\tx = self.embedding_layer(inputs, training = training)\n",
    "\t\tif states is None:\n",
    "\t\t\tbatch_size, _ = inputs.shape\n",
    "\t\t\tstates = self.gru_layer.get_initial_state(batch_size)\n",
    "\n",
    "\t\tx, states = self.gru_layer(x, initial_state = states, training = training)\n",
    "\t\ty_command = self.dense_command_layer(x, training = training)\n",
    "\t\ty_arg = self.dense_arg_layer(x, training = training)\n",
    "\n",
    "\t\tif return_state:\n",
    "\t\t\treturn y_command, y_arg, states\n",
    "\t\telse:\n",
    "\t\t\treturn y_command, y_arg\n",
    "\n",
    "# We override tf.keras.Model to allow extracting the state later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5188bd6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LanguageModel()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "876d58d5",
   "metadata": {},
   "source": [
    "## Trying the (untrained) model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "00dbe598",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<_TakeDataset element_spec=(TensorSpec(shape=(64, 81), dtype=tf.int64, name=None), (TensorSpec(shape=(64, 81), dtype=tf.int64, name=None), TensorSpec(shape=(64, 81), dtype=tf.int64, name=None)))>\n",
      "(64, 81, 3) :: (batch_size, seq_length, num_commands)\n",
      "(64, 81, 9) :: (batch_size, seq_length, num_command_args)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"language_model\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"language_model\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)           │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">81</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)           │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,760</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ gru (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GRU</span>)                       │ ((<span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">81</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>), (<span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>,   │        <span style=\"color: #00af00; text-decoration-color: #00af00\">62,208</span> │\n",
       "│                                 │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>))                  │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">81</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)            │           <span style=\"color: #00af00; text-decoration-color: #00af00\">387</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">81</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>)            │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,161</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding (\u001b[38;5;33mEmbedding\u001b[0m)           │ (\u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m81\u001b[0m, \u001b[38;5;34m32\u001b[0m)           │         \u001b[38;5;34m1,760\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ gru (\u001b[38;5;33mGRU\u001b[0m)                       │ ((\u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m81\u001b[0m, \u001b[38;5;34m128\u001b[0m), (\u001b[38;5;34m64\u001b[0m,   │        \u001b[38;5;34m62,208\u001b[0m │\n",
       "│                                 │ \u001b[38;5;34m128\u001b[0m))                  │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m81\u001b[0m, \u001b[38;5;34m3\u001b[0m)            │           \u001b[38;5;34m387\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m81\u001b[0m, \u001b[38;5;34m9\u001b[0m)            │         \u001b[38;5;34m1,161\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">65,516</span> (255.92 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m65,516\u001b[0m (255.92 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">65,516</span> (255.92 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m65,516\u001b[0m (255.92 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(dataset.take(1))\n",
    "\n",
    "for sample_inputs, expected_sample_outputs in dataset.take(1):\n",
    "\tsample_cmd_predictions, sample_arg_predictions = model(sample_inputs)\n",
    "\tprint(sample_cmd_predictions.shape, ':: (batch_size, seq_length, num_commands)')\n",
    "\tprint(sample_arg_predictions.shape, ':: (batch_size, seq_length, num_command_args)')\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fa561ba",
   "metadata": {},
   "source": [
    "Now let's inspect `sample_predictions`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1793ee51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(81, 1)\n",
      "(81,)\n"
     ]
    }
   ],
   "source": [
    "# Take one sample of the data, where sample_cmd_predictions[0] contains log probability\n",
    "sampled_cmd_indices = tf.random.categorical(sample_cmd_predictions[0], num_samples = 1)\n",
    "print(sampled_cmd_indices.shape)\n",
    "\n",
    "# tf.squeeze: Removes dimensions of size 1.\n",
    "sampled_cmd_indices = tf.squeeze(sampled_cmd_indices).numpy()\n",
    "print(sampled_cmd_indices.shape)\n",
    "\n",
    "# Do the same for the arg predictions\n",
    "sampled_arg_indices = tf.squeeze(tf.random.categorical(sample_arg_predictions[0], num_samples = 1)).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2ad136ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: no injudicious interference from any quarter ever thwarted my plans for her impro\n",
      "Next predictions: N-ox xiN!j,uDi!ciOxuxs !inteR,fexrE!n!c,e fROm aN,y [UNK]quar?ter. Ever T.h/wA.rt,eD My/ PLAxnS For HExr[UNK] i-mpRo\n"
     ]
    }
   ],
   "source": [
    "input_text = text_from_ids_in(sample_inputs[0]).numpy().decode('utf-8')\n",
    "print('Input:', input_text)\n",
    "\n",
    "sampled_commands = np.stack((sampled_cmd_indices, ids_to_chars_out(sampled_arg_indices)), axis=1)\n",
    "reconstructed = reconstruct_from_labels(input_text, sampled_commands)\n",
    "print('Next predictions:', reconstructed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c27d276d",
   "metadata": {},
   "source": [
    "Seemingly random output, as expected!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8707f29",
   "metadata": {},
   "source": [
    "## Training!\n",
    "\n",
    "We can train it now! It's a standard classification problem -- given the previous RNN state and the current character, predict the next character.\n",
    "\n",
    "We're using the `SparseCategoricalCrossentropy` loss. See https://datascience.stackexchange.com/a/41923 and perhaps https://stats.stackexchange.com/a/420730 for commentary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0b5e4b97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss pre-training (cmd): 3.0009868144989014\n",
      "loss pre-training (arg): 9.007984161376953\n"
     ]
    }
   ],
   "source": [
    "loss_fn = tf.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "\n",
    "sample_batch_cmd_mean_loss = loss_fn(expected_sample_outputs[0], sample_cmd_predictions)\n",
    "sample_batch_arg_mean_loss = loss_fn(expected_sample_outputs[1], sample_arg_predictions)\n",
    "print('loss pre-training (cmd):', float(tf.exp(sample_batch_cmd_mean_loss)))\n",
    "print('loss pre-training (arg):', float(tf.exp(sample_batch_arg_mean_loss)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5b0a3a3",
   "metadata": {},
   "source": [
    "As expected, the initial loss is large.\n",
    "\n",
    "Now we attach the loss function and an optimizer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e7a42f1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss=[loss_fn, loss_fn])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a222cd99",
   "metadata": {},
   "source": [
    "We're just about ready to train."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "00f36be7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up checkpoints\n",
    "\n",
    "checkpoint_path = './tf_model_checkpoints/checkpoint.weights.h5'\n",
    "\n",
    "checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "\tfilepath=checkpoint_path, monitor='val_loss', mode='min', save_weights_only=True, save_best_only=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "41e9c320",
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2ad20dff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/8\n",
      "\u001b[1m1049/1049\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m115s\u001b[0m 106ms/step - loss: 0.4669 - sparse_categorical_crossentropy_loss: 0.2440 - val_loss: 0.3024 - val_sparse_categorical_crossentropy_loss: 0.1278\n",
      "Epoch 2/8\n",
      "\u001b[1m1049/1049\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m131s\u001b[0m 123ms/step - loss: 0.2600 - sparse_categorical_crossentropy_loss: 0.1147 - val_loss: 0.2816 - val_sparse_categorical_crossentropy_loss: 0.1192\n",
      "Epoch 3/8\n",
      "\u001b[1m1049/1049\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 134ms/step - loss: 0.2404 - sparse_categorical_crossentropy_loss: 0.1058 - val_loss: 0.2685 - val_sparse_categorical_crossentropy_loss: 0.1129\n",
      "Epoch 4/8\n",
      "\u001b[1m1049/1049\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m123s\u001b[0m 115ms/step - loss: 0.2287 - sparse_categorical_crossentropy_loss: 0.1005 - val_loss: 0.2660 - val_sparse_categorical_crossentropy_loss: 0.1108\n",
      "Epoch 5/8\n",
      "\u001b[1m1049/1049\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m150s\u001b[0m 141ms/step - loss: 0.2206 - sparse_categorical_crossentropy_loss: 0.0972 - val_loss: 0.2601 - val_sparse_categorical_crossentropy_loss: 0.1087\n",
      "Epoch 6/8\n",
      "\u001b[1m1049/1049\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 134ms/step - loss: 0.2164 - sparse_categorical_crossentropy_loss: 0.0950 - val_loss: 0.2550 - val_sparse_categorical_crossentropy_loss: 0.1062\n",
      "Epoch 7/8\n",
      "\u001b[1m1049/1049\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m140s\u001b[0m 131ms/step - loss: 0.2119 - sparse_categorical_crossentropy_loss: 0.0935 - val_loss: 0.2489 - val_sparse_categorical_crossentropy_loss: 0.1042\n",
      "Epoch 8/8\n",
      "\u001b[1m1049/1049\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 133ms/step - loss: 0.2095 - sparse_categorical_crossentropy_loss: 0.0923 - val_loss: 0.2652 - val_sparse_categorical_crossentropy_loss: 0.1056\n"
     ]
    }
   ],
   "source": [
    "\n",
    "history = model.fit(dataset, epochs=EPOCHS, callbacks=[checkpoint_callback], validation_data=dataset_validate)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e34e041",
   "metadata": {},
   "source": [
    "## Add punctuation\n",
    "\n",
    "Let's try it!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "31a23d85",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Punctuator:\n",
    "\tdef __init__(self, model: LanguageModel, temperature: float = 1.0):\n",
    "\t\tself.temperature = temperature\n",
    "\t\tself.model = model\n",
    "\t\tself.last_states = None\n",
    "\n",
    "\t\t# See https://www.tensorflow.org/api_docs/python/tf/sparse/SparseTensor?hl=en\n",
    "\t\tskip_ids = chars_to_ids_out(['[UNK]', 'x'])\n",
    "\t\tout_vocab_size = len(chars_to_ids_out.get_vocabulary())\n",
    "\t\tprint(out_vocab_size, skip_ids)\n",
    "\t\tself.prediction_mask = tf.sparse.to_dense(tf.sparse.reorder(tf.SparseTensor(\n",
    "\t\t\tindices=tf.reshape(skip_ids, [-1, 1]), # shape [N, ndims]. This specifies the nonzero elements' indices.\n",
    "\t\t\tvalues=[float('-inf')] * len(skip_ids),\n",
    "\t\t\tdense_shape=[out_vocab_size],\n",
    "\t\t)))\n",
    "\t\n",
    "\tdef step(self, input: str|Any):\n",
    "\t\t# Data conversion\n",
    "\t\tinput_chars = tf.strings.unicode_split(input, 'UTF-8')\n",
    "\t\tinput_ids = chars_to_ids_in(input_chars)\n",
    "\t\tinput_ids = tf.reshape(input_ids, [1, -1]) # Convert to column vec\n",
    "\n",
    "\t\t# Run it!\n",
    "\t\t# predicted.shape is [batch, char, next_char_logits]\n",
    "\t\tpredicted_cmd, predicted_arg, states = self.model(inputs=input_ids, states=self.last_states, return_state=True)\n",
    "\t\tself.last_states = states\n",
    "\n",
    "\t\tprint(predicted_cmd.shape, ':: (batch_size, seq_len, num_cmds)')\n",
    "\n",
    "\t\tpredicted_next_cmd_logits = (predicted_cmd[-1, :, :]) / self.temperature\n",
    "\t\tpredicted_next_arg_logits = predicted_arg[-1, :, :] / self.temperature\n",
    "\t\tpredicted_next_arg_logits += self.prediction_mask # Sets some weights to -inf\n",
    "\n",
    "\t\tpredicted_cmd = tf.random.categorical(predicted_next_cmd_logits, num_samples=1)\n",
    "\t\tpredicted_arg_id = tf.random.categorical(predicted_next_arg_logits, num_samples=1)\n",
    "\t\tpredicted_arg = ids_to_chars_out(predicted_arg_id)\n",
    "\n",
    "\t\tpredicted_commands = np.stack((tf.squeeze(predicted_cmd), tf.squeeze(predicted_arg)), axis=1)\n",
    "\t\treturn reconstruct_from_labels(input, predicted_commands)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2d749297",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9 tf.Tensor([0 8], shape=(2,), dtype=int64)\n",
      "(1, 48, 3) :: (batch_size, seq_len, num_cmds)\n",
      "~Once upon a time a punctuatiOn. test Took place, \n",
      "(1, 49, 3) :: (batch_size, seq_len, num_cmds)\n",
      "it took long enough that the end seemed to Never \n",
      "(1, 7, 3) :: (batch_size, seq_len, num_cmds)\n",
      "arrive \n",
      "(1, 66, 3) :: (batch_size, seq_len, num_cmds)\n",
      "~I suspEct that this test Will fail miseraBly. the first few timEs, \n",
      "CPU times: user 637 ms, sys: 20.3 ms, total: 657 ms\n",
      "Wall time: 673 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "punctuator = Punctuator(model)\n",
    "\n",
    "print(punctuator.step('~once upon a time a punctuation test took place '))\n",
    "\n",
    "print(punctuator.step('it took long enough that the end seemed to never '))\n",
    "print(punctuator.step('arrive '))\n",
    "print(punctuator.step('~i suspect that this test will fail miserably the first few times '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29ee3931",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
