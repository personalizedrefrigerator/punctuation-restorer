{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "71899cc9-86b4-4eda-b525-d818661c70a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-31 01:21:18.355818: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-08-31 01:21:18.359102: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-08-31 01:21:18.369807: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-08-31 01:21:18.386761: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-08-31 01:21:18.391335: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-08-31 01:21:18.405729: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-08-31 01:21:19.232247: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa459db2-5a48-4bac-8cbd-38496888faee",
   "metadata": {},
   "source": [
    "**Notes**:\n",
    "- This notebook follows [an online tutorial](https://www.tensorflow.org/text/tutorials/nmt_with_attention) (and [at least one other](https://www.tensorflow.org/text/tutorials/text_generation) of the Tensorflow tutorials).\n",
    "- This [blog post](https://janakiev.com/blog/jupyter-virtual-envs/) was referenced to set up the virtual environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "92b150ba-48c0-4f33-8d08-b9f363d6fcfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import typing\n",
    "from typing import Any, Tuple\n",
    "from prepare_data import load_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5faca0eb-c672-4d1c-884f-b5ba38a22b63",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_raw, context_raw = load_data('./data/en/')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5890fa88",
   "metadata": {},
   "source": [
    "We store the **expected** output in `target_raw` and the input to our model in `context_raw`. Let's see an example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "55ea3dde",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Either the well was very deep, or she fell very slowly, for she had plenty of time as she went down to look about her and to wonder what was going to happen next. First, she tried to look down and make out what she was coming to, but it was too dark to see anything then she looked at the sides of the well, and noticed that they were filled with cupboards and book-shelves here and there she saw maps and pictures hung upon pegs. She took down a jar from one of the shelves as she passed it was labelled ORANGE MARMALADE , but to her great disappointment it was empty she did not like to drop the jar for fear of killing somebody underneath, so managed to put it into one of the cupboards as she fell past it.',\n",
       " 'either the well was very deep or she fell very slowly for she had plenty of time as she went down to look about her and to wonder what was going to happen next first she tried to look down and make out what she was coming to but it was too dark to see anything then she looked at the sides of the well and noticed that they were filled with cupboards and book shelves here and there she saw maps and pictures hung upon pegs she took down a jar from one of the shelves as she passed it was labelled orange marmalade but to her great disappointment it was empty she did not like to drop the jar for fear of killing somebody underneath so managed to put it into one of the cupboards as she fell past it')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_raw[12], context_raw[12]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64f129de",
   "metadata": {},
   "source": [
    "Notice that `target_raw` contains punctuation, while `context_raw` does not. Each entry is paragraph length.\n",
    "\n",
    "## Creating a dataset\n",
    "\n",
    "We begin by vectorizing our data. For now, we're working with the [text generation](https://www.tensorflow.org/text/tutorials/text_generation) tutorial and so we tokenize by characters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2e2805cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vocab size in chars: 89\n"
     ]
    }
   ],
   "source": [
    "text = ' '.join(target_raw)\n",
    "vocab = sorted(set(text))\n",
    "print('vocab size in chars:', len(vocab))\n",
    "\n",
    "chars_to_ids = tf.keras.layers.StringLookup(vocabulary=vocab)\n",
    "# Invert: Map chars to IDs instead of IDs to chars\n",
    "ids_to_chars = tf.keras.layers.StringLookup(vocabulary=chars_to_ids.get_vocabulary(), invert=True)\n",
    "\n",
    "def text_from_ids(ids: list[int]):\n",
    "\treturn tf.strings.reduce_join(ids_to_chars(ids), axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "99fc264b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(6376070,), dtype=int64, numpy=array([27, 58, 58, ..., 19, 36, 46])>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_ids = chars_to_ids(tf.strings.unicode_split(text, 'UTF-8'))\n",
    "all_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9f1626f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I l l u s t r a t i o n   A l i c e ' s   A d v e n t u r e s   "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-31 01:21:23.144104: I tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    }
   ],
   "source": [
    "# Separates all_ids along its first dimension into different items in the dataset.\n",
    "ids_dataset = tf.data.Dataset.from_tensor_slices(all_ids)\n",
    "\n",
    "# Preview the dataset -- demonstrates converting Tensors to numpy to text\n",
    "for ids in ids_dataset.take(32):\n",
    "\tprint(ids_to_chars(ids).numpy().decode('utf-8'), end = ' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dfe60be9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(b\"Illustration Alice's Adventures in Wonderland by Lewis Carroll TH\", shape=(), dtype=string)\n",
      "tf.Tensor(b'E MILLENNIUM FULCRUM EDITION 3.0 Contents CHAPTER I. Down the Rab', shape=(), dtype=string)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-31 01:21:23.183403: I tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    }
   ],
   "source": [
    "seq_length = 64\n",
    "\n",
    "# batch: Convert the dataset to sequences of the target size.\n",
    "# drop_remainder: Drop the last batch if it has fewer than 80 elements\n",
    "sequences = ids_dataset.batch(seq_length + 1, drop_remainder=True)\n",
    "\n",
    "for seq in sequences.take(2):\n",
    "\tprint(text_from_ids(seq))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f2195f8",
   "metadata": {},
   "source": [
    "We now split into a dataset of $(\\text{input}, \\text{label})$ pairs. Here, `input` is the current character and `label` is the next character (expected output)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4022cc66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(['T', 'e', 'x'], ['e', 'x', 't'])\n"
     ]
    }
   ],
   "source": [
    "def split_input_label(sequence):\n",
    "\t# Shifts the label text by 1 with respect to the input so that\n",
    "\t# entrywise pairing creates the desired (input, label).\n",
    "\tinput_text = sequence[:-1]\n",
    "\tlabel_text = sequence[1:]\n",
    "\treturn input_text, label_text\n",
    "\n",
    "print(split_input_label(list('Text')))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02270d65",
   "metadata": {},
   "source": [
    "We create our final dataset by pairing labels and input:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "27b4e3d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example input: tf.Tensor(b\"Illustration Alice's Adventures in Wonderland by Lewis Carroll T\", shape=(), dtype=string)\n",
      "Example label: tf.Tensor(b\"llustration Alice's Adventures in Wonderland by Lewis Carroll TH\", shape=(), dtype=string)\n"
     ]
    }
   ],
   "source": [
    "dataset = sequences.map(split_input_label)\n",
    "\n",
    "for example_input, example_label in dataset.take(1):\n",
    "\tprint('Example input:', text_from_ids(example_input))\n",
    "\tprint('Example label:', text_from_ids(example_label))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0854f4b3",
   "metadata": {},
   "source": [
    "## Final preprocessing\n",
    "\n",
    "We now shuffle the data, then do final batching."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a50a19ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "BUFFER_SIZE = 10000\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "dataset = dataset.shuffle(BUFFER_SIZE).batch(BATCH_SIZE, drop_remainder = True).prefetch(tf.data.AUTOTUNE)\n",
    "# Break into test and training data (no validation data for now).\n",
    "# Inspired by https://stackoverflow.com/a/74609848.\n",
    "# test_size = dataset.cardinality() * 1 // 4\n",
    "# dataset_test = dataset.take(test_size)\n",
    "# dataset = dataset.skip(test_size)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ed3f818",
   "metadata": {},
   "source": [
    "## Building the model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b47b9620",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vocab_size 90\n",
      "EMBEDDING_DIM 64\n",
      "RNN_UNITS 256\n"
     ]
    }
   ],
   "source": [
    "# .get_vocabulary: Returns a list of the characters in use.\n",
    "vocab_size = len(chars_to_ids.get_vocabulary())\n",
    "\n",
    "EMBEDDING_DIM = 64\n",
    "RNN_UNITS = 256 # Dimensionality of GRU output\n",
    "\n",
    "print('vocab_size', vocab_size)\n",
    "print('EMBEDDING_DIM', EMBEDDING_DIM)\n",
    "print('RNN_UNITS', RNN_UNITS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6287f97c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LanguageModel(tf.keras.Model):\n",
    "\tdef __init__(self, vocab_size: int, embedding_dim: int, rnn_units: int):\n",
    "\t\tsuper().__init__()\n",
    "\n",
    "\t\tself.embedding_layer = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
    "\t\t# return_sequences: Return the full sequence of outputs, rather than just the last.\n",
    "\t\t# return_state: Returns the last state in addition to the output\n",
    "\t\tself.gru_layer = tf.keras.layers.GRU(rnn_units, return_sequences=True, return_state=True)\n",
    "\t\tself.dense_layer = tf.keras.layers.Dense(vocab_size, activation=tf.keras.activations.log_softmax)\n",
    "\t\n",
    "\tdef call(self, inputs, states = None, return_state = False, training = False):\n",
    "\t\tx = self.embedding_layer(inputs, training = training)\n",
    "\t\tif states is None:\n",
    "\t\t\tbatch_size, _ = inputs.shape\n",
    "\t\t\tstates = self.gru_layer.get_initial_state(batch_size)\n",
    "\n",
    "\t\tx, states = self.gru_layer(x, initial_state = states, training = training)\n",
    "\t\tx = self.dense_layer(x, training = training)\n",
    "\n",
    "\t\tif return_state:\n",
    "\t\t\treturn x, states\n",
    "\t\telse:\n",
    "\t\t\treturn x\n",
    "\n",
    "# We override tf.keras.Model to allow extracting the state later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5188bd6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LanguageModel(vocab_size, EMBEDDING_DIM, RNN_UNITS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "876d58d5",
   "metadata": {},
   "source": [
    "## Trying the (untrained) model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "00dbe598",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 64, 90) :: (batch_size, seq_length, vocab_size)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-31 01:21:24.610774: I tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"language_model\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"language_model\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)           │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)           │         <span style=\"color: #00af00; text-decoration-color: #00af00\">5,760</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ gru (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GRU</span>)                       │ ((<span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>), (<span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>,   │       <span style=\"color: #00af00; text-decoration-color: #00af00\">247,296</span> │\n",
       "│                                 │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>))                  │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">90</span>)           │        <span style=\"color: #00af00; text-decoration-color: #00af00\">23,130</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding (\u001b[38;5;33mEmbedding\u001b[0m)           │ (\u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m)           │         \u001b[38;5;34m5,760\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ gru (\u001b[38;5;33mGRU\u001b[0m)                       │ ((\u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m256\u001b[0m), (\u001b[38;5;34m64\u001b[0m,   │       \u001b[38;5;34m247,296\u001b[0m │\n",
       "│                                 │ \u001b[38;5;34m256\u001b[0m))                  │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m90\u001b[0m)           │        \u001b[38;5;34m23,130\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">276,186</span> (1.05 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m276,186\u001b[0m (1.05 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">276,186</span> (1.05 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m276,186\u001b[0m (1.05 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for sample_input_batch, sample_label_batch in dataset.take(1):\n",
    "\tsample_predictions = model(sample_input_batch)\n",
    "\tprint(sample_predictions.shape, ':: (batch_size, seq_length, vocab_size)')\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fa561ba",
   "metadata": {},
   "source": [
    "Now let's inspect `sample_predictions`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1793ee51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 1)\n",
      "(64,)\n"
     ]
    }
   ],
   "source": [
    "# Take one sample of the (100,91) data, where sample_predictions[0] contains log probability\n",
    "sampled_indices = tf.random.categorical(sample_predictions[0], num_samples = 1)\n",
    "print(sampled_indices.shape)\n",
    "\n",
    "# tf.squeeze: Removes dimensions of size 1.\n",
    "sampled_indices = tf.squeeze(sampled_indices).numpy()\n",
    "print(sampled_indices.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2ad136ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: sensible of somewhat pungent suffering these sensations for the \n",
      "Next predictions: ÆRqY6WHù.kuæL1LAe6]DÉùzO]]Q[UNK]9,üVN?1c?5ülÆ.ŒçG.]zëiTZr/RM6qi6ùv3g\n"
     ]
    }
   ],
   "source": [
    "print('Input:', text_from_ids(sample_input_batch[0]).numpy().decode('utf-8'))\n",
    "print('Next predictions:', text_from_ids(sampled_indices).numpy().decode('utf-8'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c27d276d",
   "metadata": {},
   "source": [
    "Seemingly random output, as expected!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8707f29",
   "metadata": {},
   "source": [
    "## Training!\n",
    "\n",
    "We can train it now! It's a standard classification problem -- given the previous RNN state and the current character, predict the next character.\n",
    "\n",
    "We're using the `SparseCategoricalCrossentropy` loss. See https://datascience.stackexchange.com/a/41923 and perhaps https://stats.stackexchange.com/a/420730 for commentary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0b5e4b97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss pre-training 90.000732421875\n"
     ]
    }
   ],
   "source": [
    "loss_fn = tf.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "\n",
    "sample_batch_mean_loss = loss_fn(sample_label_batch, sample_predictions)\n",
    "print('loss pre-training', float(tf.exp(sample_batch_mean_loss)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5b0a3a3",
   "metadata": {},
   "source": [
    "As expected, the initial loss is large.\n",
    "\n",
    "Now we attach the loss function and an optimizer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e7a42f1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss=loss_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a222cd99",
   "metadata": {},
   "source": [
    "We're just about ready to train."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "00f36be7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up checkpoints\n",
    "\n",
    "checkpoint_path = './tf_model_checkpoints/checkpoint.weights.h5'\n",
    "\n",
    "checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "\tfilepath=checkpoint_path, monitor='loss', mode='min', save_weights_only=True, save_best_only=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "41e9c320",
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2ad20dff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "\u001b[1m1532/1532\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m304s\u001b[0m 198ms/step - loss: 1.3804\n",
      "Epoch 2/15\n",
      "\u001b[1m 840/1532\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m2:13\u001b[0m 193ms/step - loss: 1.3894"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[30], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mEPOCHS\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mcheckpoint_callback\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/punctuation-fixer/env/lib64/python3.11/site-packages/keras/src/utils/traceback_utils.py:117\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    116\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 117\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    118\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/Documents/punctuation-fixer/env/lib64/python3.11/site-packages/keras/src/backend/tensorflow/trainer.py:320\u001b[0m, in \u001b[0;36mTensorFlowTrainer.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[0m\n\u001b[1;32m    318\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m step, iterator \u001b[38;5;129;01min\u001b[39;00m epoch_iterator\u001b[38;5;241m.\u001b[39menumerate_epoch():\n\u001b[1;32m    319\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m--> 320\u001b[0m     logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    321\u001b[0m     logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pythonify_logs(logs)\n\u001b[1;32m    322\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_end(step, logs)\n",
      "File \u001b[0;32m~/Documents/punctuation-fixer/env/lib64/python3.11/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/Documents/punctuation-fixer/env/lib64/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:833\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    830\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    832\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 833\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    835\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    836\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m~/Documents/punctuation-fixer/env/lib64/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:878\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    875\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m    876\u001b[0m \u001b[38;5;66;03m# In this case we have not created variables on the first call. So we can\u001b[39;00m\n\u001b[1;32m    877\u001b[0m \u001b[38;5;66;03m# run the first trace but we should fail if variables are created.\u001b[39;00m\n\u001b[0;32m--> 878\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mtracing_compilation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    879\u001b[0m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_variable_creation_config\u001b[49m\n\u001b[1;32m    880\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    881\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_created_variables:\n\u001b[1;32m    882\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCreating variables on a non-first call to a function\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    883\u001b[0m                    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m decorated with tf.function.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/Documents/punctuation-fixer/env/lib64/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:139\u001b[0m, in \u001b[0;36mcall_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    137\u001b[0m bound_args \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mbind(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    138\u001b[0m flat_inputs \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39munpack_inputs(bound_args)\n\u001b[0;32m--> 139\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[1;32m    140\u001b[0m \u001b[43m    \u001b[49m\u001b[43mflat_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\n\u001b[1;32m    141\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/punctuation-fixer/env/lib64/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py:1322\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[1;32m   1318\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1319\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1320\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1321\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1322\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_preflattened\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1323\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1324\u001b[0m     args,\n\u001b[1;32m   1325\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1326\u001b[0m     executing_eagerly)\n\u001b[1;32m   1327\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[0;32m~/Documents/punctuation-fixer/env/lib64/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:216\u001b[0m, in \u001b[0;36mAtomicFunction.call_preflattened\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcall_preflattened\u001b[39m(\u001b[38;5;28mself\u001b[39m, args: Sequence[core\u001b[38;5;241m.\u001b[39mTensor]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m    215\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 216\u001b[0m   flat_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    217\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mpack_output(flat_outputs)\n",
      "File \u001b[0;32m~/Documents/punctuation-fixer/env/lib64/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:251\u001b[0m, in \u001b[0;36mAtomicFunction.call_flat\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    249\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m record\u001b[38;5;241m.\u001b[39mstop_recording():\n\u001b[1;32m    250\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[0;32m--> 251\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_bound_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    252\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    253\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    254\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction_type\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflat_outputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    256\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    257\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m make_call_op_in_graph(\n\u001b[1;32m    258\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    259\u001b[0m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[1;32m    260\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mfunction_call_options\u001b[38;5;241m.\u001b[39mas_attrs(),\n\u001b[1;32m    261\u001b[0m     )\n",
      "File \u001b[0;32m~/Documents/punctuation-fixer/env/lib64/python3.11/site-packages/tensorflow/python/eager/context.py:1552\u001b[0m, in \u001b[0;36mContext.call_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1550\u001b[0m cancellation_context \u001b[38;5;241m=\u001b[39m cancellation\u001b[38;5;241m.\u001b[39mcontext()\n\u001b[1;32m   1551\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1552\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1553\u001b[0m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1554\u001b[0m \u001b[43m      \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1555\u001b[0m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensor_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1556\u001b[0m \u001b[43m      \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1557\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1558\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1560\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m   1561\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m   1562\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1566\u001b[0m       cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_context,\n\u001b[1;32m   1567\u001b[0m   )\n",
      "File \u001b[0;32m~/Documents/punctuation-fixer/env/lib64/python3.11/site-packages/tensorflow/python/eager/execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     54\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "history = model.fit(dataset, epochs=EPOCHS, callbacks=[checkpoint_callback])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e34e041",
   "metadata": {},
   "source": [
    "## Generate text\n",
    "\n",
    "We'll run the model in a loop, keeping track of its internal state as it's executed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "31a23d85",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextGenerator:\n",
    "\tdef __init__(self, model: LanguageModel, ids_to_chars, chars_to_ids, temperature: float = 1.0):\n",
    "\t\tself.temperature = temperature\n",
    "\t\tself.model = model\n",
    "\t\tself.ids_to_chars = ids_to_chars\n",
    "\t\tself.chars_to_ids = chars_to_ids\n",
    "\t\tself.last_states = None\n",
    "\n",
    "\t\t# See https://www.tensorflow.org/api_docs/python/tf/sparse/SparseTensor?hl=en\n",
    "\t\tskip_ids = self.chars_to_ids(['[UNK]'])\n",
    "\t\tvocab_size = len(self.chars_to_ids.get_vocabulary())\n",
    "\t\tprint(vocab_size, skip_ids)\n",
    "\t\tself.prediction_mask = tf.sparse.to_dense(tf.SparseTensor(\n",
    "\t\t\tindices=[skip_ids], # shape [N, ndims]. This specifies the nonzero elements' indices.\n",
    "\t\t\tvalues=[float('-inf')] * len(skip_ids),\n",
    "\t\t\tdense_shape=[vocab_size],\n",
    "\t\t))\n",
    "\t\n",
    "\tdef step(self, input: str|Any):\n",
    "\t\t# Data conversion\n",
    "\t\tinput_chars = tf.strings.unicode_split(input, 'UTF-8')\n",
    "\t\tinput_ids = self.chars_to_ids(input_chars)\n",
    "\t\tinput_ids = tf.reshape(input_ids, [-1, 1])\n",
    "\n",
    "\t\t# Run it!\n",
    "\t\t# predicted.shape is [batch, char, next_char_logits]\n",
    "\t\tpredicted, states = self.model(inputs=input_ids, states=self.last_states, return_state=True)\n",
    "\t\tself.last_states = states\n",
    "\n",
    "\t\tpredicted_next_char_logits = predicted[-1, -1, :]\n",
    "\t\tpredicted_next_char_logits /= self.temperature\n",
    "\t\tpredicted_next_char_logits += self.prediction_mask # Sets some weights to -inf\n",
    "\n",
    "\t\tpredicted_ids = tf.random.categorical([predicted_next_char_logits], num_samples=1)\n",
    "\t\tpredicted_ids = tf.squeeze(predicted_ids)\n",
    "\n",
    "\t\tpredicted_chars = self.ids_to_chars(predicted_ids)\n",
    "\t\treturn predicted_chars\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2d749297",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "90 tf.Tensor([0], shape=(1,), dtype=int64)\n",
      "mind in all his chamble a committed that the seccuserasion more times but his ground a admire, relat\n",
      "ed for me. This marriage. Then he was not rendering the educe was alrestionate cut of our place with\n",
      " an inother little, while his noties, Vamp. Villefort was in Thé Ey, Masimore Rabous we still Morrel\n",
      " should not see Scarencians, his intention of gentleman and the eat of the ministers ascention with \n",
      "right was could knows with all persect, he remembered? The traveller see. The Arabitu autecomanty im\n",
      "agine that I mean you all my voided in-paid on his carriage a custom of course smile to say it to do\n",
      " with a doff, and felt at these giving, was not respect that it daughter to this invadience. A manne\n",
      "r. Ah, at Monte Cristo he did not always of the power of sulles, but up, you see the new viest. He p\n",
      "laced were conveyed, well?' Why. Was yet sometimes bould to France, said Madcé me which he had depen\n",
      "ded upon Josephabe, when these contrary. Ah, day I was not to see me his hand too, will by amond Alo\n",
      "CPU times: user 11.7 s, sys: 60.3 ms, total: 11.7 s\n",
      "Wall time: 12.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "text_generator = TextGenerator(model, ids_to_chars, chars_to_ids)\n",
    "next_char = 'Hello, '\n",
    "\n",
    "for i in range(10):\n",
    "\toutput = []\n",
    "\n",
    "\tfor j in range(100):\n",
    "\t\tnext_char = text_generator.step(next_char)\n",
    "\t\toutput.append(next_char)\n",
    "\n",
    "\tprint(tf.strings.join(output).numpy().decode('utf-8'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29ee3931",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
