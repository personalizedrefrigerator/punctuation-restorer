{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "71899cc9-86b4-4eda-b525-d818661c70a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-31 19:34:41.842096: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-08-31 19:34:41.845902: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-08-31 19:34:41.862187: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-08-31 19:34:41.885677: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-08-31 19:34:41.891301: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-08-31 19:34:41.905810: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-08-31 19:34:42.770257: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa459db2-5a48-4bac-8cbd-38496888faee",
   "metadata": {},
   "source": [
    "**Notes**:\n",
    "- This notebook follows [an online tutorial](https://www.tensorflow.org/text/tutorials/nmt_with_attention) (and [at least one other](https://www.tensorflow.org/text/tutorials/text_generation) of the Tensorflow tutorials).\n",
    "- This [blog post](https://janakiev.com/blog/jupyter-virtual-envs/) was referenced to set up the virtual environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "92b150ba-48c0-4f33-8d08-b9f363d6fcfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import typing\n",
    "from typing import Any, Tuple\n",
    "from prepare_data import load_data, reconstruct_from_labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5faca0eb-c672-4d1c-884f-b5ba38a22b63",
   "metadata": {},
   "outputs": [],
   "source": [
    "context_raw, target_raw = load_data('./data/en/')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5890fa88",
   "metadata": {},
   "source": [
    "We store the **expected** output in `target_raw` and the input to our model in `context_raw`. Let's see an example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7bbcb7c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['1', '2', '1', ..., '2', '1', '1'], dtype='<U1')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_raw"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab821739",
   "metadata": {},
   "source": [
    "Each element in `target_raw` is an operation (e.g. 0 = copy) followed by a character code. For example, `1` is \"capitalize\" and `0` is \"copy\". Note that `120` (`ord(x)`) is used for operations that take no arguments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "55ea3dde",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('1', 'v')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_raw[24], context_raw[24]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64f129de",
   "metadata": {},
   "source": [
    "\n",
    "## Creating a dataset\n",
    "\n",
    "We begin by vectorizing our data. `target_raw` and `context_raw` are already tokenized by characters/operations.\n",
    "\n",
    "We start by creating a vectorization for the `target_raw`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2e2805cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input vocab size in chars: 54\n"
     ]
    }
   ],
   "source": [
    "input_vocab = sorted(set(context_raw))\n",
    "print('Input vocab size in chars:', len(input_vocab))\n",
    "\n",
    "chars_to_ids_in = tf.keras.layers.StringLookup(vocabulary=input_vocab)\n",
    "# Invert: Map chars to IDs instead of IDs to chars\n",
    "ids_to_chars_in = tf.keras.layers.StringLookup(vocabulary=chars_to_ids_in.get_vocabulary(), invert=True)\n",
    "\n",
    "# in: \"Input\"\n",
    "def text_from_ids_in(ids: list[int]):\n",
    "\treturn tf.strings.reduce_join(ids_to_chars_in(ids), axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "99fc264b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(6754252,), dtype=int64, numpy=array([40, 22, 25, ..., 31, 13,  1])>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_ids_input = chars_to_ids_in(context_raw)\n",
    "all_ids_input"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "116b3a40",
   "metadata": {},
   "source": [
    "Now, we do the same for the output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1520bd75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output vocab size in chars: 11\n"
     ]
    }
   ],
   "source": [
    "output_vocab = sorted(set(target_raw))\n",
    "print('Output vocab size in chars:', len(output_vocab))\n",
    "\n",
    "chars_to_ids_out = tf.keras.layers.StringLookup(vocabulary=output_vocab)\n",
    "# Invert: Map chars to IDs instead of IDs to chars\n",
    "ids_to_chars_out = tf.keras.layers.StringLookup(vocabulary=chars_to_ids_out.get_vocabulary(), invert=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4ba83b38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['!', \"'\", ',', '-', '.', '/', '1', '2', ':', ';', '?']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(output_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5d9fde0a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(6754252,), dtype=int64, numpy=array([7, 8, 7, ..., 8, 7, 7])>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_ids_output = chars_to_ids_out(target_raw)\n",
    "all_ids_output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af035816",
   "metadata": {},
   "source": [
    "Now that we have vectorized inputs and outputs, let's create a `Dataset` we can feed to the model.\n",
    "\n",
    "First, combine the expected inputs and outputs into a single vector:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e2e72752",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(6754252, 2), dtype=int64, numpy=\n",
       "array([[40,  7],\n",
       "       [22,  8],\n",
       "       [25,  7],\n",
       "       ...,\n",
       "       [31,  8],\n",
       "       [13,  7],\n",
       "       [ 1,  7]])>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def column(v):\n",
    "\treturn tf.reshape(v, [-1, 1])\n",
    "\n",
    "ids_and_outputs = tf.concat([\n",
    "\tcolumn(all_ids_input), column(all_ids_output)\n",
    "], 1)\n",
    "ids_and_outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e45b3dd",
   "metadata": {},
   "source": [
    "Next, create a `Dataset`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9f1626f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "~ c(1), i c(2), l c(1), l c(1), u c(1), s c(1), t c(1), r c(1), a c(1), t c(1), i c(1), o c(1), n c(1),   c(1), ~ c(1), a c(2), l c(1), i c(1), c c(1), e c(1), s c('),   c(1), a c(2), d c(1), v c(1), e c(1), n c(1), t c(1), u c(1), r c(1), e c(1), s c(1), "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-31 19:34:50.214256: I tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    }
   ],
   "source": [
    "def shift_inputs(inputs: list):\n",
    "\treturn tf.concat([inputs[4:], [0, 0, 0, 0]], 0)\n",
    "\n",
    "# Separates ids_and_outputs along its first dimension into different items in the dataset.\n",
    "ids_input_main = all_ids_input\n",
    "ids_input_shifted = shift_inputs(all_ids_input)\n",
    "ids_input_shifted_twice = shift_inputs(ids_input_shifted)\n",
    "\n",
    "# Tuples: from_tensor_slices pairs entries of each tuple item to produce the dataset.\n",
    "input_dataset = tf.data.Dataset.from_tensor_slices((ids_input_main, ids_input_shifted, ids_input_shifted_twice))\n",
    "output_dataset = tf.data.Dataset.from_tensor_slices(all_ids_output)\n",
    "dataset = tf.data.Dataset.zip(input_dataset, output_dataset)\n",
    "\n",
    "# Preview the dataset -- demonstrates converting Tensors to numpy to text\n",
    "for input, expected_sample_outputs in dataset.take(32):\n",
    "\tinput_char = ids_to_chars_in(input[0]).numpy().decode('utf-8')\n",
    "\toutput_char = ids_to_chars_out(expected_sample_outputs).numpy().decode('utf-8')\n",
    "\n",
    "\tprint('{} c({})'.format(input_char, output_char), end = ', ')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dfe60be9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inputs: tf.Tensor(\n",
      "[b'~illustration ~alices adventures in wonderland ~by lewis carroll ~the millennium fulcrum edition 30 ~conte'\n",
      " b'ustration ~alices adventures in wonderland ~by lewis carroll ~the millennium fulcrum edition 30 ~contents '\n",
      " b'ation ~alices adventures in wonderland ~by lewis carroll ~the millennium fulcrum edition 30 ~contents ~cha'], shape=(3,), dtype=string)\n",
      "Inputs: tf.Tensor(\n",
      "[b'nts ~chapter i down the rabbithole chapter ii the pool of tears chapter iii a caucusrace and a long tale c'\n",
      " b'~chapter i down the rabbithole chapter ii the pool of tears chapter iii a caucusrace and a long tale chapt'\n",
      " b'pter i down the rabbithole chapter ii the pool of tears chapter iii a caucusrace and a long tale chapter i'], shape=(3,), dtype=string)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-31 19:34:50.350828: I tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    }
   ],
   "source": [
    "seq_length = 105\n",
    "\n",
    "# batch: Convert the dataset to sequences of the target size.\n",
    "# drop_remainder: Drop the last batch if it has fewer than seq_length elements\n",
    "sequences = dataset.batch(seq_length + 1, drop_remainder=True)\n",
    "\n",
    "for sample_inputs, expected_sample_outputs in sequences.take(2):\n",
    "\tprint('Inputs:', text_from_ids_in(sample_inputs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "30c9b190",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = sequences"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7db7917f",
   "metadata": {},
   "source": [
    "Our dataset now pairs inputs and labels!\n",
    "\n",
    "**Note**: This [StackOverflow](https://stackoverflow.com/questions/53171885/how-to-use-tf-data-dataset-and-tf-keras-do-multi-inputs-and-multi-outpus) question, the documentation on [Dataset.zip](https://www.tensorflow.org/api_docs/python/tf/data/Dataset?hl=en#zip), and documentation on [Dataset.from_tensor_slices](https://www.tensorflow.org/api_docs/python/tf/data/Dataset?hl=en#from_tensor_slices) were helpful."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0854f4b3",
   "metadata": {},
   "source": [
    "## Final preprocessing\n",
    "\n",
    "We now shuffle the data, then do final batching."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a50a19ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "BUFFER_SIZE = 10000\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "dataset = dataset.shuffle(BUFFER_SIZE).batch(BATCH_SIZE, drop_remainder = True).prefetch(tf.data.AUTOTUNE)\n",
    "# Break into test and training data (no validation data for now).\n",
    "# Inspired by https://stackoverflow.com/a/74609848.\n",
    "validate_size = dataset.cardinality() * 1 // 8\n",
    "dataset_validate = dataset.take(validate_size)\n",
    "dataset = dataset.skip(validate_size)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ed3f818",
   "metadata": {},
   "source": [
    "## Building the model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b47b9620",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vocab_size_in 55\n",
      "vocab_size_out 12\n",
      "EMBEDDING_DIM 64\n",
      "RNN_UNITS 64\n"
     ]
    }
   ],
   "source": [
    "# .get_vocabulary: Returns a list of the characters in use.\n",
    "vocab_size_in = len(chars_to_ids_in.get_vocabulary())\n",
    "\n",
    "vocab_size_out = len(chars_to_ids_out.get_vocabulary())\n",
    "size_out = vocab_size_out # Output includes both commands and the command arg\n",
    "\n",
    "EMBEDDING_DIM = 64\n",
    "RNN_UNITS = 64 # Dimensionality of GRU output\n",
    "\n",
    "print('vocab_size_in', vocab_size_in)\n",
    "print('vocab_size_out', vocab_size_out)\n",
    "print('EMBEDDING_DIM', EMBEDDING_DIM)\n",
    "print('RNN_UNITS', RNN_UNITS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6287f97c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LanguageModel(tf.keras.Model):\n",
    "\tdef __init__(self):\n",
    "\t\tsuper().__init__()\n",
    "\n",
    "\t\tself.embedding_layer = tf.keras.layers.Embedding(vocab_size_in, EMBEDDING_DIM)\n",
    "\t\tself.merge_layer = tf.keras.layers.Concatenate()\n",
    "\t\t# return_sequences: Return the full sequence of outputs, rather than just the last.\n",
    "\t\t# return_state: Returns the last state in addition to the output\n",
    "\t\tself.gru_layer = tf.keras.layers.GRU(RNN_UNITS, return_sequences=True, return_state=True)\n",
    "\t\tself.dense_layer = tf.keras.layers.Dense(size_out, activation=tf.keras.activations.log_softmax)\n",
    "\t\n",
    "\tdef call(self, inputs, states = None, return_state = False, training = False):\n",
    "\t\tinputs_orig, inputs_ahead, inputs_ahead_x2 = inputs\n",
    "\t\t\n",
    "\t\tx = self.merge_layer([\n",
    "\t\t\tself.embedding_layer(inputs_orig, training=training),\n",
    "\t\t\tself.embedding_layer(inputs_ahead, training=training),\n",
    "\t\t\tself.embedding_layer(inputs_ahead_x2, training=training),\n",
    "\t\t])\n",
    "\t\tif states is None:\n",
    "\t\t\tbatch_size, _ = inputs_orig.shape\n",
    "\t\t\tstates = self.gru_layer.get_initial_state(batch_size)\n",
    "\n",
    "\t\tx, states = self.gru_layer(x, initial_state = states, training = training)\n",
    "\t\tx = self.dense_layer(x, training = training)\n",
    "\n",
    "\t\tif return_state:\n",
    "\t\t\treturn x, states\n",
    "\t\telse:\n",
    "\t\t\treturn x\n",
    "\n",
    "# We override tf.keras.Model to allow extracting the state later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5188bd6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LanguageModel()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "876d58d5",
   "metadata": {},
   "source": [
    "## Trying the (untrained) model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "00dbe598",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<_TakeDataset element_spec=((TensorSpec(shape=(64, 106), dtype=tf.int64, name=None), TensorSpec(shape=(64, 106), dtype=tf.int64, name=None), TensorSpec(shape=(64, 106), dtype=tf.int64, name=None)), TensorSpec(shape=(64, 106), dtype=tf.int64, name=None))>\n",
      "(64, 106, 12) :: (batch_size, seq_length, num_commands)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"language_model\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"language_model\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)           │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">106</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          │         <span style=\"color: #00af00; text-decoration-color: #00af00\">3,520</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ concatenate (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">106</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">192</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ gru (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GRU</span>)                       │ ((<span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">106</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>), (<span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>,   │        <span style=\"color: #00af00; text-decoration-color: #00af00\">49,536</span> │\n",
       "│                                 │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>))                   │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">106</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>)          │           <span style=\"color: #00af00; text-decoration-color: #00af00\">780</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding (\u001b[38;5;33mEmbedding\u001b[0m)           │ (\u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m106\u001b[0m, \u001b[38;5;34m64\u001b[0m)          │         \u001b[38;5;34m3,520\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ concatenate (\u001b[38;5;33mConcatenate\u001b[0m)       │ (\u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m106\u001b[0m, \u001b[38;5;34m192\u001b[0m)         │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ gru (\u001b[38;5;33mGRU\u001b[0m)                       │ ((\u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m106\u001b[0m, \u001b[38;5;34m64\u001b[0m), (\u001b[38;5;34m64\u001b[0m,   │        \u001b[38;5;34m49,536\u001b[0m │\n",
       "│                                 │ \u001b[38;5;34m64\u001b[0m))                   │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m106\u001b[0m, \u001b[38;5;34m12\u001b[0m)          │           \u001b[38;5;34m780\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">53,836</span> (210.30 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m53,836\u001b[0m (210.30 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">53,836</span> (210.30 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m53,836\u001b[0m (210.30 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(dataset.take(1))\n",
    "\n",
    "for sample_inputs, expected_sample_outputs in dataset.take(1):\n",
    "\tsample_predictions = model(sample_inputs)\n",
    "\tprint(sample_predictions.shape, ':: (batch_size, seq_length, num_commands)')\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fa561ba",
   "metadata": {},
   "source": [
    "Now let's inspect `sample_predictions`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1793ee51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(106, 1)\n",
      "(106,)\n"
     ]
    }
   ],
   "source": [
    "# Take one sample of the data, where sample_cmd_predictions[0] contains log probability\n",
    "sampled_indices = tf.random.categorical(sample_predictions[0], num_samples = 1)\n",
    "print(sampled_indices.shape)\n",
    "\n",
    "# tf.squeeze: Removes dimensions of size 1.\n",
    "sampled_indices = tf.squeeze(sampled_indices).numpy()\n",
    "print(sampled_indices.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2ad136ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: covering a means of extrication but he himself looked so composed and so grave also i became ashamed of fe\n",
      "Next predictions: .c;oV?e/r,i,n-g 'a. [UNK]m,e/a-n;s /o?f, ;e'x?tr[UNK]i,c[UNK]a/t/i'on[UNK] 'b[UNK]u,t ;he' H.i!m's!e!l[UNK]f! /l/o:o.k.e'd; s/o .c'oMP[UNK]o.s/e?d, ,anD- ;s.o? .g?ra!v.e/ !a;lso- i- 'b-eca:m/e !a/s-h:a.m[UNK]e'd .of' F.e\n"
     ]
    }
   ],
   "source": [
    "input_text = text_from_ids_in(sample_inputs[0][0]).numpy().decode('utf-8')\n",
    "print('Input:', input_text)\n",
    "\n",
    "sampled_commands = ids_to_chars_out(sampled_indices).numpy()\n",
    "reconstructed = reconstruct_from_labels(input_text, sampled_commands)\n",
    "print('Next predictions:', reconstructed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c27d276d",
   "metadata": {},
   "source": [
    "Seemingly random output, as expected!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8707f29",
   "metadata": {},
   "source": [
    "## Training!\n",
    "\n",
    "We can train it now! It's a standard classification problem -- given the previous RNN state and the current character, predict the next character.\n",
    "\n",
    "We're using the `SparseCategoricalCrossentropy` loss. See https://datascience.stackexchange.com/a/41923 and perhaps https://stats.stackexchange.com/a/420730 for commentary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0b5e4b97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss pre-training: 12.003934860229492\n"
     ]
    }
   ],
   "source": [
    "loss_fn = tf.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "\n",
    "sample_batch_mean_loss = loss_fn(expected_sample_outputs, sample_predictions)\n",
    "print('loss pre-training:', float(tf.exp(sample_batch_mean_loss)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5b0a3a3",
   "metadata": {},
   "source": [
    "As expected, the initial loss is large.\n",
    "\n",
    "Now we attach the loss function and an optimizer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e7a42f1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss=loss_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a222cd99",
   "metadata": {},
   "source": [
    "We're just about ready to train."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "00f36be7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up checkpoints\n",
    "\n",
    "checkpoint_path = './tf_model_checkpoints/checkpoint.weights.h5'\n",
    "\n",
    "checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "\tfilepath=checkpoint_path, monitor='val_loss', mode='min', save_weights_only=True, save_best_only=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "41e9c320",
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2ad20dff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m871/871\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m102s\u001b[0m 112ms/step - loss: 0.3242 - val_loss: 0.2103\n",
      "Epoch 2/20\n",
      "\u001b[1m871/871\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m100s\u001b[0m 111ms/step - loss: 0.1665 - val_loss: 0.1948\n",
      "Epoch 3/20\n",
      "\u001b[1m871/871\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m101s\u001b[0m 113ms/step - loss: 0.1507 - val_loss: 0.1844\n",
      "Epoch 4/20\n",
      "\u001b[1m871/871\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 92ms/step - loss: 0.1406 - val_loss: 0.1754\n",
      "Epoch 5/20\n",
      "\u001b[1m871/871\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 87ms/step - loss: 0.1358 - val_loss: 0.1717\n",
      "Epoch 6/20\n",
      "\u001b[1m871/871\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 87ms/step - loss: 0.1312 - val_loss: 0.1723\n",
      "Epoch 7/20\n",
      "\u001b[1m871/871\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 89ms/step - loss: 0.1281 - val_loss: 0.1683\n",
      "Epoch 8/20\n",
      "\u001b[1m871/871\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m97s\u001b[0m 108ms/step - loss: 0.1260 - val_loss: 0.1661\n",
      "Epoch 9/20\n",
      "\u001b[1m871/871\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m99s\u001b[0m 110ms/step - loss: 0.1238 - val_loss: 0.1629\n",
      "Epoch 10/20\n",
      "\u001b[1m871/871\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m98s\u001b[0m 108ms/step - loss: 0.1221 - val_loss: 0.1615\n",
      "Epoch 11/20\n",
      "\u001b[1m871/871\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m99s\u001b[0m 110ms/step - loss: 0.1213 - val_loss: 0.1629\n",
      "Epoch 12/20\n",
      "\u001b[1m871/871\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m100s\u001b[0m 111ms/step - loss: 0.1197 - val_loss: 0.1638\n",
      "Epoch 13/20\n",
      "\u001b[1m871/871\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m141s\u001b[0m 110ms/step - loss: 0.1183 - val_loss: 0.1589\n",
      "Epoch 14/20\n",
      "\u001b[1m871/871\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 109ms/step - loss: 0.1182 - val_loss: 0.1599\n",
      "Epoch 15/20\n",
      "\u001b[1m871/871\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m99s\u001b[0m 110ms/step - loss: 0.1178 - val_loss: 0.1570\n",
      "Epoch 16/20\n",
      "\u001b[1m871/871\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m96s\u001b[0m 106ms/step - loss: 0.1170 - val_loss: 0.1600\n",
      "Epoch 17/20\n",
      "\u001b[1m871/871\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m103s\u001b[0m 115ms/step - loss: 0.1170 - val_loss: 0.1557\n",
      "Epoch 18/20\n",
      "\u001b[1m871/871\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m97s\u001b[0m 107ms/step - loss: 0.1149 - val_loss: 0.1554\n",
      "Epoch 19/20\n",
      "\u001b[1m871/871\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m99s\u001b[0m 110ms/step - loss: 0.1148 - val_loss: 0.1552\n",
      "Epoch 20/20\n",
      "\u001b[1m871/871\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 88ms/step - loss: 0.1144 - val_loss: 0.1572\n"
     ]
    }
   ],
   "source": [
    "\n",
    "history = model.fit(dataset, epochs=EPOCHS, callbacks=[checkpoint_callback], validation_data=dataset_validate)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e34e041",
   "metadata": {},
   "source": [
    "## Add punctuation\n",
    "\n",
    "Let's try it!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "31a23d85",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Punctuator:\n",
    "\tdef __init__(self, model: LanguageModel, temperature: float = 1.0):\n",
    "\t\tself.temperature = temperature\n",
    "\t\tself.model = model\n",
    "\t\tself.last_states = None\n",
    "\n",
    "\t\t# See https://www.tensorflow.org/api_docs/python/tf/sparse/SparseTensor?hl=en\n",
    "\t\tskip_ids = chars_to_ids_out(['[UNK]'])\n",
    "\t\tout_vocab_size = len(chars_to_ids_out.get_vocabulary())\n",
    "\t\tprint(out_vocab_size, skip_ids)\n",
    "\t\tself.prediction_mask = tf.sparse.to_dense(tf.sparse.reorder(tf.SparseTensor(\n",
    "\t\t\tindices=tf.reshape(skip_ids, [-1, 1]), # shape [N, ndims]. This specifies the nonzero elements' indices.\n",
    "\t\t\tvalues=[float('-inf')] * len(skip_ids),\n",
    "\t\t\tdense_shape=[out_vocab_size],\n",
    "\t\t)))\n",
    "\t\n",
    "\tdef step(self, input: str|Any):\n",
    "\t\t# Data conversion\n",
    "\t\tinput_chars = tf.strings.unicode_split(input, 'UTF-8')\n",
    "\t\tinput_ids = chars_to_ids_in(input_chars)\n",
    "\t\tshifted_input_ids = shift_inputs(input_ids)\n",
    "\t\tshifted_twice_input_ids = shift_inputs(shifted_input_ids)\n",
    "\t\tinputs = (\n",
    "\t\t\ttf.reshape(input_ids, [1, -1]),\n",
    "\t\t\ttf.reshape(shifted_input_ids, [1, -1]),\n",
    "\t\t\ttf.reshape(shifted_twice_input_ids, [1, -1]),\n",
    "\t\t)\n",
    "\n",
    "\t\t# Run it!\n",
    "\t\t# predicted.shape is [batch, char, next_char_logits]\n",
    "\t\tpredicted_commands_raw, states = self.model(inputs=inputs, states=self.last_states, return_state=True)\n",
    "\t\tself.last_states = states\n",
    "\n",
    "\t\t# print(predicted_cmd.shape, ':: (batch_size, seq_len, num_cmds)')\n",
    "\n",
    "\t\tpredicted_logits = (predicted_commands_raw[-1, :, :]) / self.temperature\n",
    "\t\tpredicted_logits += self.prediction_mask # Sets some weights to -inf\n",
    "\n",
    "\t\tpredicted_commands = tf.squeeze(tf.random.categorical(predicted_logits, num_samples=1))\n",
    "\t\treturn reconstruct_from_labels(input, ids_to_chars_out(predicted_commands).numpy())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "2d749297",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12 tf.Tensor([0], shape=(1,), dtype=int64)\n",
      "~The punctuator is a small machine learning model for punctuation restoration at present its performance\n",
      " Is rather poor I do hope however that with additional training, and very little rearchitecting the punct\n",
      "uator will be a usable and fast model. ~I suspect that I will need to look into the neural machine transl\n",
      "ation tutorials will the approach taken by the example Seq2seq model for Spanish, to English translation. \n",
      "Be sufficient will, I need to learn about transformers ~Note, there are concerns about model size in addit\n",
      "ion to performance as Model's will need to be run on mobile devices. ~The punctuator was trained on old bo\n",
      "oks does prose of a similar style work better heres some text from Frankenstein. ~Although it denieD WaRM\n",
      "tH Safie AgathA and FelIx departed on a long country walk ~Interesting perhaps It isnt any better in tha\n",
      "t case How unfortunATE \n",
      "CPU times: user 2.24 s, sys: 134 ms, total: 2.38 s\n",
      "Wall time: 2.44 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "punctuator = Punctuator(model, temperature=0.5)\n",
    "\n",
    "text = '''~the punctuator is a small machine learning model for punctuation restoration\n",
    "at present its performance is rather poor i do hope however that with additional training\n",
    "and very little rearchitecting the punctuator will be a usable and fast model\n",
    "~i suspect that i will need to look into the neural machine translation tutorials will the\n",
    "approach taken by the example seq2seq model for spanish to english translation be sufficient\n",
    "will i need to learn about transformers\n",
    "~note there are concerns about model size in addition to performance as models will need to be run\n",
    "on mobile devices\n",
    "~the punctuator was trained on old books does prose of a similar style work better heres some text from\n",
    "frankenstein\n",
    "~although it denied warmth safie agatha and felix departed on a long country walk\n",
    "~interesting perhaps it isnt any better in that case how unfortunate\n",
    "'''\n",
    "text = text.replace('\\n', ' ')\n",
    "\n",
    "step_size = seq_length - 1\n",
    "for i in range(0, len(text), step_size):\n",
    "\tprint(punctuator.step(text[i:(i+step_size)]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "892384e9",
   "metadata": {},
   "source": [
    "That isn't working very well. For comparison, let's try an example from the training data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "29ee3931",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "up somewhere ~down down down there was nothing else to do so alice soon began talking again dinahll \n",
      "UP sOMeWHerE. ~Down down down there was nothing else to Do so Alice soon began talking again dinahll \n"
     ]
    }
   ],
   "source": [
    "orig = tf.strings.reduce_join(context_raw[4400:4500]).numpy().decode('utf-8')\n",
    "print(orig)\n",
    "print(punctuator.step(orig))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84a031ff",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
