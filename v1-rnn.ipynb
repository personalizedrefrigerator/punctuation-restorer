{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "71899cc9-86b4-4eda-b525-d818661c70a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-01 13:19:46.729584: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-09-01 13:19:46.732574: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-09-01 13:19:46.741594: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-09-01 13:19:46.756655: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-09-01 13:19:46.760760: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-09-01 13:19:46.771911: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-09-01 13:19:47.600545: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa459db2-5a48-4bac-8cbd-38496888faee",
   "metadata": {},
   "source": [
    "**Notes**:\n",
    "- This notebook follows [an online tutorial](https://www.tensorflow.org/text/tutorials/nmt_with_attention) (and [at least one other](https://www.tensorflow.org/text/tutorials/text_generation) of the Tensorflow tutorials).\n",
    "- This [blog post](https://janakiev.com/blog/jupyter-virtual-envs/) was referenced to set up the virtual environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "92b150ba-48c0-4f33-8d08-b9f363d6fcfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import typing\n",
    "from typing import Any, Tuple\n",
    "from prepare_data import load_data, reconstruct_from_labels, preprocess_text\n",
    "from IPython.display import display, Markdown\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5faca0eb-c672-4d1c-884f-b5ba38a22b63",
   "metadata": {},
   "outputs": [],
   "source": [
    "context_raw, target_raw = load_data('./data/en/')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5890fa88",
   "metadata": {},
   "source": [
    "We store the **expected** output in `target_raw` and the input to our model in `context_raw`. Let's see an example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7bbcb7c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['1', '2', '1', ..., '1', '1', '.'], dtype='<U1')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_raw"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab821739",
   "metadata": {},
   "source": [
    "Each element in `target_raw` is an operation (e.g. 0 = copy) followed by a character code. For example, `1` is \"capitalize\" and `0` is \"copy\". Note that `120` (`ord(x)`) is used for operations that take no arguments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "55ea3dde",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('1', 'v')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_raw[24], context_raw[24]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64f129de",
   "metadata": {},
   "source": [
    "\n",
    "## Creating a dataset\n",
    "\n",
    "We begin by vectorizing our data. `target_raw` and `context_raw` are already tokenized by characters/operations.\n",
    "\n",
    "We start by creating a vectorization for the `target_raw`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2e2805cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input vocab size in chars: 54\n"
     ]
    }
   ],
   "source": [
    "input_vocab = sorted(set(context_raw))\n",
    "print('Input vocab size in chars:', len(input_vocab))\n",
    "\n",
    "chars_to_ids_in = tf.keras.layers.StringLookup(vocabulary=input_vocab)\n",
    "# Invert: Map chars to IDs instead of IDs to chars\n",
    "ids_to_chars_in = tf.keras.layers.StringLookup(vocabulary=chars_to_ids_in.get_vocabulary(), invert=True)\n",
    "\n",
    "# in: \"Input\"\n",
    "def text_from_ids_in(ids: list[int]):\n",
    "\treturn tf.strings.reduce_join(ids_to_chars_in(ids), axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "99fc264b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(7252805,), dtype=int64, numpy=array([40, 22, 25, ..., 16, 18,  1])>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_ids_input = chars_to_ids_in(context_raw)\n",
    "all_ids_input"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "116b3a40",
   "metadata": {},
   "source": [
    "Now, we do the same for the output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1520bd75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output vocab size in chars: 8\n"
     ]
    }
   ],
   "source": [
    "output_vocab = sorted(set(target_raw))\n",
    "print('Output vocab size in chars:', len(output_vocab))\n",
    "\n",
    "chars_to_ids_out = tf.keras.layers.StringLookup(vocabulary=output_vocab)\n",
    "# Invert: Map chars to IDs instead of IDs to chars\n",
    "ids_to_chars_out = tf.keras.layers.StringLookup(vocabulary=chars_to_ids_out.get_vocabulary(), invert=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4ba83b38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"'\", ',', '-', '.', '1', '2', ':', '?']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(output_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5d9fde0a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(7252805,), dtype=int64, numpy=array([5, 6, 5, ..., 5, 5, 4])>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_ids_output = chars_to_ids_out(target_raw)\n",
    "all_ids_output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af035816",
   "metadata": {},
   "source": [
    "Now that we have vectorized inputs and outputs, let's create a `Dataset` we can feed to the model.\n",
    "\n",
    "First, combine the expected inputs and outputs into a single vector:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e2e72752",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(7252805, 2), dtype=int64, numpy=\n",
       "array([[40,  5],\n",
       "       [22,  6],\n",
       "       [25,  5],\n",
       "       ...,\n",
       "       [16,  5],\n",
       "       [18,  5],\n",
       "       [ 1,  4]])>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def column(v):\n",
    "\treturn tf.reshape(v, [-1, 1])\n",
    "\n",
    "ids_and_outputs = tf.concat([\n",
    "\tcolumn(all_ids_input), column(all_ids_output)\n",
    "], 1)\n",
    "ids_and_outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e45b3dd",
   "metadata": {},
   "source": [
    "Next, create a `Dataset`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9f1626f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "~ c(1), i c(2), l c(1), l c(1), u c(1), s c(1), t c(1), r c(1), a c(1), t c(1), i c(1), o c(1), n c(1),   c(1), ~ c(1), a c(2), l c(1), i c(1), c c(1), e c(1), s c('),   c(1), a c(2), d c(1), v c(1), e c(1), n c(1), t c(1), u c(1), r c(1), e c(1), s c(1), "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-01 13:19:55.462029: I tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    }
   ],
   "source": [
    "# Separates ids_and_outputs along its first dimension into different items in the dataset.\n",
    "ids_input_main = all_ids_input\n",
    "\n",
    "# Tuples: from_tensor_slices pairs entries of each tuple item to produce the dataset.\n",
    "input_dataset = tf.data.Dataset.from_tensor_slices(ids_input_main)\n",
    "output_dataset = tf.data.Dataset.from_tensor_slices(all_ids_output)\n",
    "dataset = tf.data.Dataset.zip(input_dataset, output_dataset)\n",
    "\n",
    "# Preview the dataset -- demonstrates converting Tensors to numpy to text\n",
    "for input, expected_sample_outputs in dataset.take(32):\n",
    "\tinput_char = ids_to_chars_in(input).numpy().decode('utf-8')\n",
    "\toutput_char = ids_to_chars_out(expected_sample_outputs).numpy().decode('utf-8')\n",
    "\n",
    "\tprint('{} c({})'.format(input_char, output_char), end = ', ')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dfe60be9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inputs: tf.Tensor(b'~illustration ~alices adventures in wonderland ~by lewis carroll ~the millennium fulcrum edition 30 ~contents', shape=(), dtype=string)\n",
      "Inputs: tf.Tensor(b'~chapter i down the rabbithole chapter ii the pool of tears chapter iii a caucusrace and a long tale chapter ', shape=(), dtype=string)\n",
      "Inputs: tf.Tensor(b'iv the rabbit sends in a little bill chapter v advice from a caterpillar chapter vi pig and pepper chapter v ', shape=(), dtype=string)\n",
      "Inputs: tf.Tensor(b'a mad teaparty chapter viii the queens croquetground chapter ix the mock turtles story chapter x the lobst   ', shape=(), dtype=string)\n",
      "Inputs: tf.Tensor(b'quadrille chapter xi who stole the tarts chapter xii alices evidence ~chapter i down the rabbithole ~alice   ', shape=(), dtype=string)\n",
      "Inputs: tf.Tensor(b'was beginning to get very tired of sitting by her sister on the bank and of having nothing to do once or twi ', shape=(), dtype=string)\n",
      "Inputs: tf.Tensor(b'she had peeped into the book her sister was reading but it had no pictures or conversations in it and what   ', shape=(), dtype=string)\n",
      "Inputs: tf.Tensor(b'is the use of a book thought alice without pictures or conversations ~so she was considering in her own mind ', shape=(), dtype=string)\n",
      "Inputs: tf.Tensor(b'as well as she could for the hot day made her feel very sleepy and stupid whether the pleasure of making a d ', shape=(), dtype=string)\n",
      "Inputs: tf.Tensor(b'would be worth the trouble of getting up and picking the daisies when suddenly a white rabbit with           ', shape=(), dtype=string)\n",
      "Inputs: tf.Tensor(b'eyes ran close by her ~there was nothing so very remarkable in that nor did alice think it so very much      ', shape=(), dtype=string)\n",
      "Inputs: tf.Tensor(b'of the way to hear the rabbit say to itself oh dear oh dear i shall be late when she thought it over afte    ', shape=(), dtype=string)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-01 13:19:55.652834: I tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    }
   ],
   "source": [
    "seq_length = 108\n",
    "\n",
    "# batch: Convert the dataset to sequences of the target size.\n",
    "# drop_remainder: Drop the last batch if it has fewer than seq_length elements\n",
    "sequences = dataset.batch(seq_length + 1, drop_remainder=True)\n",
    "\n",
    "# Roll each sequence so that it starts with a word or paragraph.\n",
    "space_id_in = int(chars_to_ids_in([' '])[0])\n",
    "parbreak_id_in = int(chars_to_ids_in(['~'])[0])\n",
    "\n",
    "\n",
    "def shift_left_by(s, amount: int):\n",
    "\tpadding = space_id_in * tf.ones([amount], dtype = tf.dtypes.int64)\n",
    "\treturn tf.concat((s[amount:], padding), axis=0)\n",
    "\n",
    "def word_align_sequences(in_seq, out_seq):\n",
    "\tfirst_space_index = tf.math.argmax(in_seq == space_id_in, axis=0)\n",
    "\t# Include a virtual paragraph break at the end of [a]. This means that first_paragraph_index\n",
    "\t# will be a large number if no paragraph break is found.\n",
    "\tparagraph_matches = tf.concat((in_seq == parbreak_id_in, [True]), axis=0)\n",
    "\tfirst_parbreak_index = tf.math.argmax(paragraph_matches, axis=0)\n",
    "\n",
    "\troll_amount = tf.math.minimum(first_space_index + 1, first_parbreak_index)\n",
    "\tmap_sequence = lambda s: shift_left_by(s, roll_amount)\n",
    "\n",
    "\treturn map_sequence(in_seq), map_sequence(out_seq)\n",
    "sequences = sequences.map(word_align_sequences)\n",
    "\n",
    "for sample_inputs, expected_sample_outputs in sequences.take(12):\n",
    "\tprint('Inputs:', text_from_ids_in(sample_inputs))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a78e505b",
   "metadata": {},
   "source": [
    "Now we have word-aligned training data! To make things a bit easier on our model, let's also give it access to the next few characters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8597ee74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: tf.Tensor(b'~illustration ~alices adventures in wonderland ~by lewis carroll ~the millennium fulcrum edition 30 ~contents', shape=(), dtype=string)\n",
      "Input: tf.Tensor(b'ation ~alices adventures in wonderland ~by lewis carroll ~the millennium fulcrum edition 30 ~contents        ', shape=(), dtype=string)\n"
     ]
    }
   ],
   "source": [
    "shifts_features_amounts = [ 0, 8 ]\n",
    "def add_lookahead_to_input(input):\n",
    "\tmapped_inputs = []\n",
    "\tfor shift in shifts_features_amounts:\n",
    "\t\tmapped_inputs.append(shift_left_by(input, shift))\n",
    "\treturn tuple(mapped_inputs)\n",
    "\n",
    "def add_character_lookahead_features(input, output):\n",
    "\treturn add_lookahead_to_input(input), output\n",
    "sequences_with_lookahead = sequences.map(add_character_lookahead_features)\n",
    "\n",
    "\n",
    "for sample_inputs, expected_sample_outputs in sequences_with_lookahead.take(1):\n",
    "\tfor item in sample_inputs:\n",
    "\t\tprint('Input:', text_from_ids_in(item))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "30c9b190",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = sequences_with_lookahead"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7db7917f",
   "metadata": {},
   "source": [
    "Our dataset now pairs inputs and labels!\n",
    "\n",
    "**Note**: This [StackOverflow](https://stackoverflow.com/questions/53171885/how-to-use-tf-data-dataset-and-tf-keras-do-multi-inputs-and-multi-outpus) question, the documentation on [Dataset.zip](https://www.tensorflow.org/api_docs/python/tf/data/Dataset?hl=en#zip), and documentation on [Dataset.from_tensor_slices](https://www.tensorflow.org/api_docs/python/tf/data/Dataset?hl=en#from_tensor_slices) were helpful."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0854f4b3",
   "metadata": {},
   "source": [
    "## Final preprocessing\n",
    "\n",
    "We now shuffle the data, then do final batching."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a50a19ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "BUFFER_SIZE = 10000\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "dataset = dataset.shuffle(BUFFER_SIZE).batch(BATCH_SIZE, drop_remainder = True).prefetch(tf.data.AUTOTUNE)\n",
    "# Break into test and training data (no validation data for now).\n",
    "# Inspired by https://stackoverflow.com/a/74609848.\n",
    "validate_size = dataset.cardinality() * 1 // 8\n",
    "dataset_validate = dataset.take(validate_size)\n",
    "dataset = dataset.skip(validate_size)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ed3f818",
   "metadata": {},
   "source": [
    "## Building the model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b47b9620",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vocab_size_in 55\n",
      "vocab_size_out 9\n",
      "EMBEDDING_DIM 128\n",
      "RNN_UNITS 128\n"
     ]
    }
   ],
   "source": [
    "# .get_vocabulary: Returns a list of the characters in use.\n",
    "vocab_size_in = len(chars_to_ids_in.get_vocabulary())\n",
    "\n",
    "vocab_size_out = len(chars_to_ids_out.get_vocabulary())\n",
    "size_out = vocab_size_out # Output includes both commands and the command arg\n",
    "\n",
    "EMBEDDING_DIM = 128\n",
    "RNN_UNITS = 128 # Dimensionality of GRU output\n",
    "\n",
    "print('vocab_size_in', vocab_size_in)\n",
    "print('vocab_size_out', vocab_size_out)\n",
    "print('EMBEDDING_DIM', EMBEDDING_DIM)\n",
    "print('RNN_UNITS', RNN_UNITS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6287f97c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LanguageModel(tf.keras.Model):\n",
    "\tdef __init__(self):\n",
    "\t\tsuper().__init__()\n",
    "\n",
    "\t\tself.embedding_layer = tf.keras.layers.Embedding(vocab_size_in, EMBEDDING_DIM)\n",
    "\t\tself.merge_layer = tf.keras.layers.Concatenate()\n",
    "\n",
    "\t\t# return_sequences: Return the full sequence of outputs, rather than just the last.\n",
    "\t\t# return_state: Returns the last state in addition to the output\n",
    "\t\tself.gru_layer = tf.keras.layers.GRU(RNN_UNITS, return_sequences=True, return_state=True)\n",
    "\t\tself.dense_layer = tf.keras.layers.Dense(size_out, activation=tf.keras.activations.log_softmax)\n",
    "\t\n",
    "\tdef call(self, inputs, states = None, return_state = False, training = False):\n",
    "\t\tx = self.merge_layer(\n",
    "\t\t\tlist(map(lambda x: self.embedding_layer(x, training=training), inputs))\n",
    "\t\t)\n",
    "\t\tif states is None:\n",
    "\t\t\tbatch_size, _ = inputs[0].shape\n",
    "\t\t\tstates = self.gru_layer.get_initial_state(batch_size)\n",
    "\n",
    "\t\tx, states = self.gru_layer(x, initial_state = states, training = training)\n",
    "\t\tx = self.dense_layer(x, training = training)\n",
    "\n",
    "\t\tif return_state:\n",
    "\t\t\treturn x, states\n",
    "\t\telse:\n",
    "\t\t\treturn x\n",
    "\n",
    "# We override tf.keras.Model to allow extracting the state later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5188bd6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LanguageModel()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "876d58d5",
   "metadata": {},
   "source": [
    "## Trying the (untrained) model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "00dbe598",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<_TakeDataset element_spec=((TensorSpec(shape=(64, None), dtype=tf.int64, name=None), TensorSpec(shape=(64, None), dtype=tf.int64, name=None)), TensorSpec(shape=(64, None), dtype=tf.int64, name=None))>\n",
      "(64, 109, 9) :: (batch_size, seq_length, num_commands)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-01 13:19:59.405356: I tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"language_model\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"language_model\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)           │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">109</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)         │         <span style=\"color: #00af00; text-decoration-color: #00af00\">7,040</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ concatenate (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">109</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ gru (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GRU</span>)                       │ ((<span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">109</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>), (<span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>,  │       <span style=\"color: #00af00; text-decoration-color: #00af00\">148,224</span> │\n",
       "│                                 │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>))                  │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">109</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>)           │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,161</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding (\u001b[38;5;33mEmbedding\u001b[0m)           │ (\u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m109\u001b[0m, \u001b[38;5;34m128\u001b[0m)         │         \u001b[38;5;34m7,040\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ concatenate (\u001b[38;5;33mConcatenate\u001b[0m)       │ (\u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m109\u001b[0m, \u001b[38;5;34m256\u001b[0m)         │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ gru (\u001b[38;5;33mGRU\u001b[0m)                       │ ((\u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m109\u001b[0m, \u001b[38;5;34m128\u001b[0m), (\u001b[38;5;34m64\u001b[0m,  │       \u001b[38;5;34m148,224\u001b[0m │\n",
       "│                                 │ \u001b[38;5;34m128\u001b[0m))                  │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m109\u001b[0m, \u001b[38;5;34m9\u001b[0m)           │         \u001b[38;5;34m1,161\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">156,425</span> (611.04 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m156,425\u001b[0m (611.04 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">156,425</span> (611.04 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m156,425\u001b[0m (611.04 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(dataset.take(1))\n",
    "\n",
    "for sample_inputs, expected_sample_outputs in dataset.take(1):\n",
    "\tsample_predictions = model(sample_inputs)\n",
    "\tprint(sample_predictions.shape, ':: (batch_size, seq_length, num_commands)')\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fa561ba",
   "metadata": {},
   "source": [
    "Now let's inspect `sample_predictions`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1793ee51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(109, 1)\n",
      "(109,)\n"
     ]
    }
   ],
   "source": [
    "# Take one sample of the data, where sample_cmd_predictions[0] contains log probability\n",
    "sampled_indices = tf.random.categorical(sample_predictions[0], num_samples = 1)\n",
    "print(sampled_indices.shape)\n",
    "\n",
    "# tf.squeeze: Removes dimensions of size 1.\n",
    "sampled_indices = tf.squeeze(sampled_indices).numpy()\n",
    "print(sampled_indices.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2ad136ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: fair play whatever i did that idea would bother me it was so tiresomely pertinacious that i resolved on requ \n",
      "Next predictions: 'f.a.iR ?p'l'a-y- .w'h,a[UNK]t:e[UNK]v'e'r. [UNK]i, .di,d- :tH?a-t. -i[UNK]d?e[UNK]a[UNK] .w[UNK]ou?l.d- -b[UNK]o?t,hE-r- ,m?e. ,i:t' ,w-a-s[UNK] -s,o ,ti[UNK]r,eS?o,m.e,l:y- PE:r[UNK]t-i,na:c.i[UNK]o,u-s? ,t[UNK]ha-t? 'i[UNK] [UNK]r,e,so-lV.e-d? ,o-n .rE'qu[UNK] \n"
     ]
    }
   ],
   "source": [
    "input_text = text_from_ids_in(sample_inputs[0][0]).numpy().decode('utf-8')\n",
    "print('Input:', input_text)\n",
    "\n",
    "sampled_commands = ids_to_chars_out(sampled_indices).numpy()\n",
    "reconstructed = reconstruct_from_labels(input_text, sampled_commands)\n",
    "print('Next predictions:', reconstructed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c27d276d",
   "metadata": {},
   "source": [
    "Seemingly random output, as expected!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8707f29",
   "metadata": {},
   "source": [
    "## Training!\n",
    "\n",
    "We can train it now! It's a standard classification problem -- given the previous RNN state and the current character, predict the next character.\n",
    "\n",
    "We're using the `SparseCategoricalCrossentropy` loss. See https://datascience.stackexchange.com/a/41923 and perhaps https://stats.stackexchange.com/a/420730 for commentary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0b5e4b97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss pre-training: 8.997515678405762\n"
     ]
    }
   ],
   "source": [
    "loss_fn = tf.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "\n",
    "sample_batch_mean_loss = loss_fn(expected_sample_outputs, sample_predictions)\n",
    "print('loss pre-training:', float(tf.exp(sample_batch_mean_loss)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5b0a3a3",
   "metadata": {},
   "source": [
    "As expected, the initial loss is large.\n",
    "\n",
    "Now we attach the loss function and an optimizer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e7a42f1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss=loss_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a222cd99",
   "metadata": {},
   "source": [
    "We're just about ready to train."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "00f36be7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up checkpoints\n",
    "\n",
    "checkpoint_path = './tf_model_checkpoints/checkpoint.weights.h5'\n",
    "\n",
    "checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "\tfilepath=checkpoint_path, monitor='val_loss', mode='min', save_weights_only=True, save_best_only=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "41e9c320",
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2ad20dff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m910/910\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m145s\u001b[0m 155ms/step - loss: 0.2683 - val_loss: 0.1879\n",
      "Epoch 2/10\n",
      "\u001b[1m910/910\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m123s\u001b[0m 132ms/step - loss: 0.1506 - val_loss: 0.1680\n",
      "Epoch 3/10\n",
      "\u001b[1m910/910\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m144s\u001b[0m 156ms/step - loss: 0.1340 - val_loss: 0.1584\n",
      "Epoch 4/10\n",
      "\u001b[1m910/910\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m220s\u001b[0m 176ms/step - loss: 0.1232 - val_loss: 0.1492\n",
      "Epoch 5/10\n",
      "\u001b[1m910/910\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m161s\u001b[0m 174ms/step - loss: 0.1173 - val_loss: 0.1471\n",
      "Epoch 6/10\n",
      "\u001b[1m910/910\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m123s\u001b[0m 133ms/step - loss: 0.1147 - val_loss: 0.1434\n",
      "Epoch 7/10\n",
      "\u001b[1m910/910\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m124s\u001b[0m 133ms/step - loss: 0.1103 - val_loss: 0.1434\n",
      "Epoch 8/10\n",
      "\u001b[1m910/910\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m126s\u001b[0m 136ms/step - loss: 0.1084 - val_loss: 0.1424\n",
      "Epoch 9/10\n",
      "\u001b[1m910/910\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m124s\u001b[0m 134ms/step - loss: 0.1070 - val_loss: 0.1379\n",
      "Epoch 10/10\n",
      "\u001b[1m910/910\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m124s\u001b[0m 133ms/step - loss: 0.1042 - val_loss: 0.1362\n"
     ]
    }
   ],
   "source": [
    "\n",
    "history = model.fit(dataset, epochs=EPOCHS, callbacks=[checkpoint_callback], validation_data=dataset_validate)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e34e041",
   "metadata": {},
   "source": [
    "## Add punctuation\n",
    "\n",
    "Let's try it!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "31a23d85",
   "metadata": {},
   "outputs": [],
   "source": [
    "def logits_to_text(original: str, predicted_logits):\n",
    "\tpredicted_commands = tf.squeeze(tf.random.categorical(predicted_logits, num_samples=1))\n",
    "\treturn reconstruct_from_labels(original, ids_to_chars_out(predicted_commands).numpy())\n",
    "\n",
    "class Punctuator:\n",
    "\tdef __init__(self, model: LanguageModel, temperature: float = 1.0):\n",
    "\t\tself.temperature = temperature\n",
    "\t\tself.model = model\n",
    "\t\tself.last_states = None\n",
    "\n",
    "\t\t# See https://www.tensorflow.org/api_docs/python/tf/sparse/SparseTensor?hl=en\n",
    "\t\tskip_ids = chars_to_ids_out(['[UNK]'])\n",
    "\t\tout_vocab_size = len(chars_to_ids_out.get_vocabulary())\n",
    "\t\tprint(out_vocab_size, skip_ids)\n",
    "\t\tself.prediction_mask = tf.sparse.to_dense(tf.sparse.reorder(tf.SparseTensor(\n",
    "\t\t\tindices=tf.reshape(skip_ids, [-1, 1]), # shape [N, ndims]. This specifies the nonzero elements' indices.\n",
    "\t\t\tvalues=[float('-inf')] * len(skip_ids),\n",
    "\t\t\tdense_shape=[out_vocab_size],\n",
    "\t\t)))\n",
    "\t\n",
    "\tdef step(self, input: str|Any):\n",
    "\t\t# Data conversion\n",
    "\t\tinput_chars = tf.strings.unicode_split(input, 'UTF-8')\n",
    "\t\tinput_ids = chars_to_ids_in(input_chars)\n",
    "\t\treshape_vec = lambda x: tf.reshape(x, [1, -1])\n",
    "\t\tinputs = tuple(map(reshape_vec, add_lookahead_to_input(input_ids)))\n",
    "\n",
    "\t\t# Run it!\n",
    "\t\t# predicted.shape is [batch, char, next_char_logits]\n",
    "\t\tpredicted_commands_raw, states = self.model(inputs=inputs, states=self.last_states, return_state=True)\n",
    "\t\tself.last_states = states\n",
    "\n",
    "\t\tpredicted_logits = (predicted_commands_raw[-1, :, :]) / self.temperature\n",
    "\t\tpredicted_logits += self.prediction_mask # Sets some weights to -inf\n",
    "\n",
    "\t\treturn predicted_logits\n",
    "\n",
    "\tdef step_and_predict(self, original: str):\n",
    "\t\treturn logits_to_text(self.step(self, original))\n",
    "\n",
    "class CombinedPunctuator:\n",
    "\tdef __init__(self, model):\n",
    "\t\tself.punctuators = [\n",
    "\t\t\tPunctuator(model, temperature = 1.0),\n",
    "\t\t\tPunctuator(model, temperature = 0.8),\n",
    "\t\t\tPunctuator(model, temperature = 0.4),\n",
    "\t\t]\n",
    "\n",
    "\tdef step(self, text: str):\n",
    "\t\tstep_size = seq_length - 1\n",
    "\t\tnum_punctuators = len(self.punctuators)\n",
    "\t\ttext_length = len(text)\n",
    "\n",
    "\t\tall_logits = np.zeros([ text_length, vocab_size_out ])\n",
    "\n",
    "\t\tfor i in range(0, text_length, step_size):\n",
    "\t\t\tshift = -5\n",
    "\t\t\tfor punctuator in self.punctuators:\n",
    "\t\t\t\tfrom_idx = max(0, i + shift)\n",
    "\t\t\t\tto_idx = min(text_length - 1, i + step_size + shift)\n",
    "\n",
    "\t\t\t\ttext_shifted = text[from_idx:to_idx]\n",
    "\t\t\t\twhile len(text_shifted) < step_size:\n",
    "\t\t\t\t\ttext_shifted += ' '\n",
    "\t\t\t\t\n",
    "\t\t\t\tpredicted_logits = punctuator.step(text_shifted)\n",
    "\t\t\t\tsliced_prediction = predicted_logits[0:to_idx-from_idx]\n",
    "\n",
    "\t\t\t\tall_logits[from_idx:to_idx] = all_logits[from_idx:to_idx] + (sliced_prediction / num_punctuators)\n",
    "\t\t\t\tshift += 5\n",
    "\t\t\t\t\t\n",
    "\t\treturn logits_to_text(text, all_logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2d749297",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9 tf.Tensor([0], shape=(1,), dtype=int64)\n",
      "9 tf.Tensor([0], shape=(1,), dtype=int64)\n",
      "9 tf.Tensor([0], shape=(1,), dtype=int64)\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "~The punctuator is a small machine, learning Model for punctuation restoration. at present, its performance is rather poor I do hope However, that with additional training, and very little rearchitecting the punctuator will be a usable and fast Model. ~I suspect that I will need to look into the neural machine, translation tutorials will the approach taken by the example seq2seq Model for spanish to English translation, be sufficient will i need to Learn about transformers. ~Note there are concerns about Model size in addition to performance as models will need to be run on mobile Devices. ~The punctuatOr was trained on old books does prose of a similar style work better Heres some text from frankenstein. ~Although it Denied Warmth, Safie Agatha and felix departed on a long country walk. ~Interesting perhaps, it Isnt any better in that case, How unfortunate : "
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5.42 s, sys: 475 ms, total: 5.9 s\n",
      "Wall time: 5.92 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "punctuator = CombinedPunctuator(model)\n",
    "\n",
    "text = '''~the punctuator is a small machine learning model for punctuation restoration\n",
    "at present its performance is rather poor i do hope however that with additional training\n",
    "and very little rearchitecting the punctuator will be a usable and fast model\n",
    "~i suspect that i will need to look into the neural machine translation tutorials will the\n",
    "approach taken by the example seq2seq model for spanish to english translation be sufficient\n",
    "will i need to learn about transformers\n",
    "~note there are concerns about model size in addition to performance as models will need to be run\n",
    "on mobile devices\n",
    "~the punctuator was trained on old books does prose of a similar style work better heres some text from\n",
    "frankenstein\n",
    "~although it denied warmth safie agatha and felix departed on a long country walk\n",
    "~interesting perhaps it isnt any better in that case how unfortunate \n",
    "'''\n",
    "text = text.replace('\\n', ' ')\n",
    "\n",
    "display(Markdown(punctuator.step(text)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "892384e9",
   "metadata": {},
   "source": [
    "That isn't working very well. For comparison, let's try an example from the training data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "29ee3931",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "up somewhere ~down down down there was nothing else to do so alice soon began talking again dinahll miss me very much tonight i should think dinah was the cat i hope theyll remember her saucer of milk at teatime dinah my dear i wish you were down here with me there are no mice in the air im afraid but you might catch a bat and thats very like a mouse you know but do cats eat bats i wonder and here alice began to get rather sleepy and went on saying to herself in a dreamy sort of way do cats eat bats do cats eat bats and sometimes do bats eat cats for you see as she couldnt answer either question it didnt much matter which way she put it she felt that she was dozing off and had just begun to dream that she was walking hand in hand with dinah and saying to her very earnestly now dinah tell me the truth did you ever eat a bat when suddenly thump thump down she came upon a heap of sticks and dry leaves and the fall was over ~alice was not a bit hurt and she jumped up on to her feet in a moment she looked up but it was all dark overhead before her was another long passage and the white ra\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "up somewhere? ~Down down down there was nothing else to do so, alice soon began talking again dinahll miss me very much tonight, I should think dinah was the cat, I hope theyll remember her saucer of milk at teatime dinah my dear I wish you were down here with me there are no mice in the air, I'm afraid, but you might catch a bat and thats very like a mouse. you know but do cats eat bats I Wonder and here alice began to get rather sleepy, and went on saying to herself in a dreamy sort of way. Do Cats eat, bats do Cats eat Bats, and sometimes do bats eat cats for you see, as she couldn't answer either question. it didn't much Matter which way she put it she felt that she was dozing off, and had just begun to dream that she was walking hand in hand with dinah, and saying to her very earnestly Now dinah tell me, the truth did you ever eat a bat When suddenly thump thump down she came upon a heap of sticks, and dry leaves, and the fall was over. ~Alice was not a bit hurt, and she jumped up on to her feet in a moment she looked up but it was all dark overhead before her was another long passage and the white r[UNK]a"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "orig = tf.strings.reduce_join(context_raw[4400:5500]).numpy().decode('utf-8')\n",
    "print(orig)\n",
    "display(Markdown(punctuator.step(orig)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84a031ff",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
